{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9283fc78",
   "metadata": {},
   "source": [
    "# Information Retrieval on Verses of the Holy Quran\n",
    "Team Labs 2022 : \n",
    "Mohammed Abdul Khaliq,\n",
    "Ufkun Bayram Menderes,\n",
    "Muhammad Saad Magdi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6837b71d",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c52d184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import math\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import collections\n",
    "from collections import Counter\n",
    "import more_itertools\n",
    "\n",
    "import time\n",
    "\n",
    "import nltk \n",
    "import regex as re\n",
    "\n",
    "\n",
    "\n",
    "#IMPORTANT VARIABLES TO TINKER\n",
    "use_loaded_inverted_index = 1 #change this to 0 to run the invertedindex code and not make use of preconstructed inverted index\n",
    "use_loaded_tfidf = 1 #change this to 0 if you would like the program to compute tfidf from scratch (can take 2-3mins)\n",
    "use_loaded_spacy_maps=1 #change this to 0 if you would like to run spacy mapping from scratch (can take >30mins)\n",
    "use_verse_suggestion = 3 #(1 = verse similarity, 2 = preprocessed explanation similarity, 3 = unpreprocessed similarity)\n",
    "\n",
    "\n",
    "subset_size = 1137 #the amount of rows to be taken from the humongous dataset (0 - for full dataset)\n",
    "samples_invindex = 7 #the amount of samples of the inverted index to display (0 - for full inverted index)\n",
    "samples_postlist = 7 #the amount of samples of postings list to display (0 - for full posting list)\n",
    "samples_intersect = 7 #the amount of text samples of intersection to display (0 - all intersected tweets)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "english_sw = stopwords.words('english')\n",
    "\n",
    "\n",
    "\n",
    "class PostList(list):\n",
    "\n",
    "    def add_new_arrival(self, sublist):\n",
    "        self.append(sublist)    #append tuple to self\n",
    "\n",
    "    def message_count(self):\n",
    "        return len(self)\n",
    "    \n",
    "#global postinglist\n",
    "#postlinglist=PostList()\n",
    "\n",
    "#postinglist = [[] for i in range(len(tokenwords))] #initialising an empty list of list which will be our posting list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9fff724e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (2.3.7)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy) (7.4.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy) (60.2.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy) (4.62.3)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy) (2.26.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy) (1.0.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy) (1.0.6)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy) (1.21.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy) (0.7.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.9)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.2 is available.\n",
      "You should consider upgrading via the '/opt/homebrew/Caskroom/miniforge/base/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting en_core_web_sm==2.3.1\n",
      "  Using cached en_core_web_sm-2.3.1-py3-none-any.whl\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from en_core_web_sm==2.3.1) (2.3.7)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.6)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.9.0)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (60.2.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.26.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.6)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.62.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.21.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.6)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.7.5)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.9)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.2 is available.\n",
      "You should consider upgrading via the '/opt/homebrew/Caskroom/miniforge/base/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/en_core_web_sm\n",
      "-->\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/spacy/data/en\n",
      "You can now load the model via spacy.load('en')\n",
      "Collecting en_core_web_lg==2.3.1\n",
      "  Using cached en_core_web_lg-2.3.1-py3-none-any.whl\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from en_core_web_lg==2.3.1) (2.3.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (0.7.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (3.0.6)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (60.2.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (4.62.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.0.6)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.0.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.21.5)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (7.4.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2.0.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2.26.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.26.7)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.2 is available.\n",
      "You should consider upgrading via the '/opt/homebrew/Caskroom/miniforge/base/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_lg')\n",
      "Collecting en_core_web_lg==2.3.1\n",
      "  Using cached en_core_web_lg-2.3.1-py3-none-any.whl\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from en_core_web_lg==2.3.1) (2.3.7)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2.0.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (4.62.3)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (7.4.5)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.0.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.21.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (0.7.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (0.9.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (3.0.6)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (60.2.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2.26.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (3.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_lg')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 22.2 is available.\n",
      "You should consider upgrading via the '/opt/homebrew/Caskroom/miniforge/base/bin/python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install spacy\n",
    "!{sys.executable} -m spacy download en \n",
    "\n",
    "!python3 -m spacy download en_core_web_lg\n",
    "\n",
    "import spacy.cli\n",
    "spacy.cli.download(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cc7317",
   "metadata": {},
   "source": [
    "## Construction of Posting List and Inverted Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55da96ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INDEX FUNCTION\n",
    "def index(filename):\n",
    "    \n",
    "    print(\"Reading file...\")\n",
    "    \n",
    "    global df\n",
    "    global new_df\n",
    "    \n",
    "    df = pd.read_csv(filename)\n",
    "    \n",
    "    #print(df)\n",
    "    \n",
    "    if (subset_size == 0):\n",
    "        new_df = df\n",
    "    else:\n",
    "        new_df = df[0:subset_size]\n",
    "    print(new_df)\n",
    "    \n",
    "    #Preprocessing and adding new column \"Clean Tweets\" which will form our searchable tokens and \"Original Text\", which will preserve our text in string form.\n",
    "    print(\"Removing NEWLINE and TAB\")\n",
    "    new_df['Text'] = new_df['Tafsir'].str.replace(r'\\d+','')\n",
    "    new_df[\"Text\"] = new_df['Tafsir'].str.replace('NEWLINE','')\n",
    "    new_df[\"Text\"] = new_df['Tafsir'].str.replace('TAB','')\n",
    "    new_df[\"Text\"] = new_df['Tafsir'].str.replace('_','')\n",
    "    \n",
    "    \n",
    "    print(\"Removing Punctuations\")\n",
    "    new_df[\"Text\"] = new_df['Text'].str.replace('[^\\w\\s]','')\n",
    "    new_df[\"Text\"] = new_df['Text'].str.replace('\\n','')\n",
    "    new_df['Text']= new_df['Text'].str.lower()\n",
    "    \n",
    "    print(\"Removing stopwords\")\n",
    "    new_df['Clean_Text'] = new_df['Text'].apply(lambda x: ' '.join([word for word in str(x).split() if word not in (english_sw)]))\n",
    "    \n",
    "    print(\"Tokenizing and creating new columns...\")\n",
    "    new_df['Original_Text']=new_df['Text']\n",
    "    new_df['Text']=new_df['Text'].apply(word_tokenize)\n",
    "    new_df['Clean_Text']=new_df['Clean_Text'].apply(word_tokenize)\n",
    "    \n",
    "    \n",
    "    #Initialising global precedence to some important variables\n",
    "    global counts\n",
    "    global tokendict\n",
    "    global tokendict1\n",
    "    global tokenwords\n",
    "    global postsizes\n",
    "    \n",
    "    tokenslist = new_df['Clean_Text'].to_list() #creating a list of list out of tweet tokens\n",
    "    flatlist = list(np.concatenate(tokenslist)) #creating a 1D list to count all unique tokens\n",
    "    counts = Counter(flatlist) #counting tokens\n",
    "    \n",
    "    tokendict = dict(counts) #creating a dictionary of key=token and value=occurences\n",
    "    \n",
    "    tokenwords = sorted(list(tokendict.keys())) #extracting only tokens from the dict and making a list of all token words in alphabetical order. This will also act as a hashmap to arrange a token to a specific id (index in this case).\n",
    "    \n",
    "    inv_dict={} #our soon to be inverted index\n",
    "\n",
    "    postinglist=[[] for i in range(len(tokenwords))] #initialising an empty list of list which will be our posting list\n",
    "\n",
    "    \n",
    "    \n",
    "    #Creating Posting List :\n",
    "    '''\n",
    "    The idea is to iterate over each row in the dataframe. We pick the tokens from the Clean_Text column\n",
    "    and check the tokens of the original tweet to see if a token does exist.\n",
    "    If it does exist, we make note of the index of the dataframe (document number) and see if the posting list already has a value\n",
    "    for this document number at the position determined by tokenwords. The position determined by tokenwords will determine which of the lists\n",
    "    of list corresponds to which token and will fill exactly that list whenever a token appears.\n",
    "    '''\n",
    "    \n",
    "    for index, rows in new_df.iterrows():\n",
    "    \n",
    "        print('Creating Posting List : %d/100' %(round(index/1000)), end='\\r')\n",
    "    \n",
    "        for item in new_df['Clean_Text'][index]:\n",
    "        \n",
    "            if item in new_df['Text'][index]:\n",
    "                \n",
    "                if index not in postinglist[tokenwords.index(item)]:\n",
    "                    postinglist[tokenwords.index(item)].append(index)\n",
    "                    \n",
    "    #Posting List Created!\n",
    "                    \n",
    "    postsizes=[len(x) for x in postinglist] #Retrieves size of each of the lists for each token is posting list\n",
    "    \n",
    "    zip_iterator = zip(tokenwords, postsizes)\n",
    "\n",
    "\n",
    "    tokendict1 = dict(zip_iterator) #Creates a dictionary with key = 'token' and value = 'size of posting list for that token'\n",
    "        \n",
    "    #NEW LINES\n",
    "    postlist1 = PostList()\n",
    "    postlist1.add_new_arrival(postinglist)\n",
    "    \n",
    "    #print(postlist1[0][2])\n",
    "    print(\"Successfully created posting list!\")\n",
    "    \n",
    "    \n",
    "    #Creating Inverted Index\n",
    "    '''\n",
    "    The inverted index is now simply created as a dictionary with the following attributes:\n",
    "    key = 'token' extracted from tokendict1(our zipped dict)\n",
    "    value = a list of lists with the firstlist having one element equal to the 'size' of the posting list taken from postsizes and\n",
    "            the second list having all the postings taken from postinglist.\n",
    "    '''\n",
    "    \n",
    "    i=0\n",
    "    for word in tokenwords:\n",
    "        if word in tokendict:\n",
    "            print('Building Inverted Index : %d/100' %(round((i/220540)*100)), end='\\r')\n",
    "            inv_dict[word]=[]\n",
    "            # append the new number to the existing array at this slot\n",
    "            inv_dict[word].append(tokendict1[word])\n",
    "            #NEW LINE\n",
    "            inv_dict[word].append(postlist1[0][tokenwords.index(word)])\n",
    "        \n",
    "            i=i+1\n",
    "    \n",
    "    print(\"Successfully Built Inverted Index\")\n",
    "                  \n",
    "    return (inv_dict, postinglist)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ff0518",
   "metadata": {},
   "source": [
    "## Query Function to Return Results From Inverted Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ff28ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUERY FUNCTION which takes two terms, by default term2=None in case only one argument is passed\n",
    "def newest_query(termlist, explanation):\n",
    "    \n",
    "    \n",
    "    #If only one argument is passed.\n",
    "    if len(termlist)==1:\n",
    "        chapverlist = []\n",
    "        doclist=[]\n",
    "        term1 = termlist[0]\n",
    "        #print(\"\\nPostings List for '\" + term1 + \"' is as follows :\")\n",
    "        #print(postlist[tokenwords.index(term1)])\n",
    "        if term1 in tokenwords:\n",
    "            for i in postlist[tokenwords.index(term1)]:\n",
    "                if explanation==1:\n",
    "                    print(\"\\nChapter : \" + str(new_df['Chapter'].iloc[i]))\n",
    "                    print(\"VerseNo. : \" + str(new_df['Verse'].iloc[i]))\n",
    "                    print(\"\\nVerse : \" + str(new_df['Translation'].iloc[i]))\n",
    "                    print(\"\\nTafsir :\" + str(new_df['Tafsir'].iloc[i]))\n",
    "                    print(\"--------------------------------------------------\")\n",
    "                    \n",
    "                chapver = '0'+ str(new_df['Chapter'].iloc[i]) + str(new_df['Verse'].iloc[i])\n",
    "                chapverlist.append(chapver)\n",
    "                doclist.append(i)\n",
    "                \n",
    "            \n",
    "            return (chapverlist,doclist) #returns the postlist result for the specific token as determined by tokenwords (our basic hashmap) index for that word.\n",
    "        else:\n",
    "            return (chapverlist, doclist)\n",
    "    \n",
    "    \n",
    "        \n",
    "    else: \n",
    "        chapverlist=[]\n",
    "        \n",
    "        collectedpostlists = []\n",
    "        \n",
    "        for i in range (0, len(termlist)):\n",
    "            #if postlist[tokenwords.index(termlist[i])]:\n",
    "            if termlist[i] in tokenwords:\n",
    "                collectedpostlists.append(postlist[tokenwords.index(termlist[i])])\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "                        \n",
    "                        \n",
    "        \n",
    "        #collectedpostlists.append(postlist[tokenwords.index(termlist[i])])\n",
    "            \n",
    "            \n",
    "        #postlist_t1 = postlist[tokenwords.index(term1)] #Retreive postlist of term1\n",
    "        #postlist_t2 = postlist[tokenwords.index(term2)] #Retrieve postlist of term2\n",
    "    \n",
    "        #Get lengths of postlists\n",
    "        #len_t1 = len(postlist_t1) \n",
    "        #len_t2 = len(postlist_t2)\n",
    "    \n",
    "        #Create an iterator for postlists\n",
    "        #iter_t1 = iter(postlist_t1)\n",
    "        #iter_t2 = iter(postlist_t2)\n",
    "        \n",
    "        if collectedpostlists:\n",
    "            intersectlist=list(set.intersection(*[set(x) for x in collectedpostlists]))  #Our soon to be intersection of both postlists.\n",
    "        else:\n",
    "            return chapverlist\n",
    "        \n",
    "        #print(intersectlist)\n",
    "        \n",
    "        #print(intersectlist)\n",
    "        #Initialising iterators with first value of both postlists\n",
    "        #i1 = next(iter_t1) \n",
    "        #i2 = next(iter_t2)\n",
    "        \n",
    "        \n",
    "        #PostList Intersection Logic\n",
    "        '''\n",
    "        We first check if both the iterators represent the same term. If they do, they get added to the intersection list.\n",
    "        If not, the iterator with the smaller value goes to its next posting. This continues till both lists are exhausted.\n",
    "        '''\n",
    "        '''\n",
    "        for i in range(0, len_t1+len_t2):\n",
    "            if (i1==i2):\n",
    "                intersectlist.append(i1)\n",
    "                i1=next(iter_t1,0)\n",
    "                i2=next(iter_t2,0)\n",
    "            elif (i1>i2):\n",
    "                i2=next(iter_t2,0)\n",
    "            elif(i2>i1):\n",
    "                i1=next(iter_t1,0)\n",
    "        '''\n",
    "        \n",
    "        #PostList Intersection Completed\n",
    "                    \n",
    "        #print(\"\\nIntersection List for '\" + term1 +\"' and '\" + term2 +\"' is as follows :\")\n",
    "        #print(intersectlist)\n",
    "        \n",
    "        #print(\"\\nExamples : \")\n",
    "        \n",
    "        samples = new_df[['Chapter', 'Verse', 'Translation','Tafsir']].iloc[intersectlist]\n",
    "        \n",
    "            \n",
    "        if (len(intersectlist)!=0):\n",
    "            \n",
    "            for i in range(0,len(intersectlist)):\n",
    "                if explanation==1:\n",
    "                    print(\"\\nChapter : \" + str(samples['Chapter'].iloc[i]))\n",
    "                    print(\"VerseNo. : \" + str(samples['Verse'].iloc[i]))\n",
    "                    print(\"\\nVerse :\\n \" + str(samples['Translation'].iloc[i]))\n",
    "                    print(\"\\nTafsir :\\n\" + str(samples['Tafsir'].iloc[i]))\n",
    "                    print(\"--------------------------------------------------\")\n",
    "                \n",
    "                chapver = '0'+ str(samples['Chapter'].iloc[i]) + str(samples['Verse'].iloc[i])\n",
    "                chapverlist.append(chapver)\n",
    "            \n",
    "                #if(i==samples_intersect):\n",
    "                #    break\n",
    "        \n",
    "        return(chapverlist, intersectlist)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87da4597",
   "metadata": {},
   "source": [
    "# Constructing/Loading Inverted Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "982d7a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading inverted index from file...\n",
      "Loading postings list from file...\n",
      "Loading relevant tokenwords from file...\n",
      "Loading preprocessed dataset...\n",
      "\n",
      " First 7 elements of inverted index\n",
      "[('0d', [1, [63]]), ('0l', [3, [145, 146, 147]]), ('1', [22, [0, 7, 202, 241, 261, 293, 294, 295, 296, 385, 386, 387, 493, 503, 669, 670, 789, 790, 791, 954, 955, 956]]), ('10', [18, [16, 302, 303, 499, 500, 501, 502, 675, 676, 677, 678, 679, 795, 796, 797, 798, 799, 963]]), ('100', [16, [105, 106, 107, 108, 109, 392, 393, 589, 590, 591, 592, 768, 769, 770, 888, 1053]]), ('1007', [3, [1125, 1126, 1127]]), ('101', [14, [105, 106, 107, 108, 109, 392, 393, 593, 768, 769, 770, 889, 1054, 1055]])]\n",
      "\n",
      "First 7 elements of posting list\n",
      "[[63], [145, 146, 147], [0, 7, 202, 241, 261, 293, 294, 295, 296, 385, 386, 387, 493, 503, 669, 670, 789, 790, 791, 954, 955, 956], [16, 302, 303, 499, 500, 501, 502, 675, 676, 677, 678, 679, 795, 796, 797, 798, 799, 963], [105, 106, 107, 108, 109, 392, 393, 589, 590, 591, 592, 768, 769, 770, 888, 1053], [1125, 1126, 1127], [105, 106, 107, 108, 109, 392, 393, 593, 768, 769, 770, 889, 1054, 1055]]\n",
      "Completed in 0.3160 seconds\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "global postlist \n",
    "\n",
    "result=[]\n",
    "\n",
    "tic = time.perf_counter()\n",
    "\n",
    "invertedindex = {}\n",
    "postlist=[]\n",
    "\n",
    "if use_loaded_inverted_index == 1:\n",
    "    print('Loading inverted index from file...')\n",
    "    with open(\"../pickle/inverted_index\", \"rb\") as fp:   # Unpickling\n",
    "       invertedindex = pickle.load(fp)\n",
    "    \n",
    "    print('Loading postings list from file...')\n",
    "    with open(\"../pickle/postlist\", \"rb\") as fp:   # Unpickling\n",
    "        postlist = pickle.load(fp)\n",
    "        \n",
    "    print('Loading relevant tokenwords from file...')\n",
    "    with open(\"../pickle/tokenwords\", \"rb\") as fp:   # Unpickling\n",
    "        tokenwords = pickle.load(fp)\n",
    "    \n",
    "    print('Loading preprocessed dataset...')\n",
    "    new_df = pd.read_pickle('../pickle/new_df')\n",
    "    \n",
    "else:\n",
    "    invertedindex, postlist = index('../data/Quran.csv') #postlist stores the posting list, invertedindex stores the complete inverted index.\n",
    "\n",
    "\n",
    "#Printing first n elements of each (samples_invindex variable under IMPORTANT VARIABLES) and showing how index matching is synchronous (hashmap between tokenwords and posting list is a success).\n",
    "if (samples_invindex==0):\n",
    "    print(\"Full inverted index:\")\n",
    "    print(inverted_index)\n",
    "else:\n",
    "    print(\"\\n First %d elements of inverted index\" %samples_invindex)\n",
    "    n_items = more_itertools.take(samples_invindex, invertedindex.items())\n",
    "    print(n_items)\n",
    "        \n",
    "if (samples_postlist == 0):\n",
    "    print(\"Full postings list:\")\n",
    "    print(postlist)\n",
    "else:\n",
    "    print(\"\\nFirst %d elements of posting list\" %samples_postlist)\n",
    "    print(postlist[:samples_postlist])\n",
    "    \n",
    "    \n",
    "    \n",
    "#result = query( \"nation\") #Returns complete postlist for a single term\n",
    "#print(result)\n",
    "\n",
    "#result = query( \"sin\", \"forgive\") #Returns intersection of postlist of both terms.\n",
    "\n",
    "toc = time.perf_counter()\n",
    "print(f\"Completed in {toc - tic:0.4f} seconds\")\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cce2503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5772b99d",
   "metadata": {},
   "source": [
    "## Spelling Correction and Linguistic Variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56147040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import itertools\n",
    "import numpy as np\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "\n",
    "nlp =spacy.load('en_core_web_lg')\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "tokenizer = nlp.tokenizer\n",
    "\n",
    "df=pd.read_csv('../data/Quran.csv')\n",
    "tokens = set(list((itertools.chain(*[[t.text for t in tokenizer(row.lower()) if t.is_alpha] for row in df[~df.Tafsir.isna()].Tafsir.to_list()]))))\n",
    "\n",
    "\n",
    "def levenshtein(token1, token2):\n",
    "    size_x = len(token1) + 1\n",
    "    size_y = len(token2) + 1\n",
    "    matrix = np.zeros ((size_x, size_y))\n",
    "    for x in range(size_x):\n",
    "        matrix [x, 0] = x\n",
    "    for y in range(size_y):\n",
    "        matrix [0, y] = y\n",
    "\n",
    "    for x in range(1, size_x):\n",
    "        for y in range(1, size_y):\n",
    "            if token1[x-1] == token2[y-1]:\n",
    "                matrix [x,y] = min(\n",
    "                    matrix[x-1, y] + 1,\n",
    "                    matrix[x-1, y-1],\n",
    "                    matrix[x, y-1] + 1\n",
    "                )\n",
    "            else:\n",
    "                matrix [x,y] = min(\n",
    "                    matrix[x-1, y] + 1,\n",
    "                    matrix[x-1, y-1] + 1,\n",
    "                    matrix[x, y-1] + 1\n",
    "                )\n",
    "    # print (matrix)\n",
    "    return (matrix[size_x - 1, size_y - 1])\n",
    "\n",
    "def spell_recommendation(query_token):\n",
    "    scores  = {}\n",
    "    for t in tokens:\n",
    "        lev_dist = levenshtein(t, query_token)\n",
    "        if lev_dist <= 1:\n",
    "            scores[t] = lev_dist\n",
    "            print(scores)\n",
    "    return [i[0] for i in sorted(scores.items(), key=lambda kv: (kv[1], kv[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a9d6fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "variation_dict = {('aadam'):'adam',\n",
    "                    ('eve', 'hava'):'hawa',\n",
    "                    ('enoch', 'idrees', 'edris', 'idrissa'): 'idris',\n",
    "                    ('noah', 'nooh'): 'nuh',\n",
    "                    ('hud', 'hood') : 'hud',\n",
    "                    ('saleh', 'shaleh', 'sawleh') : 'salih',\n",
    "                    ('abraham', 'ibraheem', 'ebrahem', 'ebrahim'): 'ibrahim',\n",
    "                    ('lot'): 'lut',\n",
    "                    ('ishmael', 'ismaeel', 'ismayl'): 'ismail',\n",
    "                    ('isaac', 'ishaaq') : 'ishaq',\n",
    "                    ('jacob', 'yaqoob', 'jakob', 'jakov', 'yakoob', 'yakub') : 'yaqub',\n",
    "                    ('joseph', 'yousuf', 'yousef', 'yosef', 'josef', 'yoseph', 'yusof') : 'yusuf',\n",
    "                    ('job', 'ayub', 'ayoob', 'ayyoob'): 'ayyub',\n",
    "                    ('jethro', 'suhaib', 'shoaib', 'suhayb', 'shuaib'): 'shu`ayb',\n",
    "                    ('moses', 'musha', 'moosa') : 'musa',\n",
    "                    ('pharoah', 'firaun', 'pharoh'):'firawn',\n",
    "                    ('david', 'davud', 'dawid'): 'dawud',\n",
    "                    ('sulaiman') : 'solomon',\n",
    "                    ('elisha'): 'ilyas',\n",
    "                    ('jonah'): 'yunus',\n",
    "                    ('zachariah', 'zakkariya', 'zacharia', 'zakariah', 'zakkariah'): 'zakariyya',\n",
    "                    ('john'): 'yahya',\n",
    "                    ('eesa', 'jesus'): 'isa', \n",
    "                    ('bakka', 'bakkah', 'mecca', 'makka') : 'makkah',\n",
    "                    ('mohammed', 'muhammed', 'mohammad', 'mohd'): 'muhammad'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a9406b",
   "metadata": {},
   "source": [
    "## Ranking\n",
    "Ranking algorithm that makes use of the sum of substring matching (highest weight) and cosine similarity between query and result to reorder the results in order of decreasing relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55cc5ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0d', 0.01251085071635225),\n",
       "             ('0l', 0.014124635331576613),\n",
       "             ('1', 0.02108461771795344),\n",
       "             ('10', 0.05245781428953969),\n",
       "             ('100', 0.01811609978316517),\n",
       "             ('1007', 0.00862573150019946),\n",
       "             ('101', 0.014190486205404347),\n",
       "             ('10101', 0.005415147175207684),\n",
       "             ('10108', 0.011139842786270969),\n",
       "             ('101611', 0.013049530121060278),\n",
       "             ('102', 0.013592710609358592),\n",
       "             ('1022', 0.00639847580139371),\n",
       "             ('1028', 0.007068495482240984),\n",
       "             ('103', 0.03864373475578862),\n",
       "             ('1030', 0.007068495482240984),\n",
       "             ('1031', 0.015684134628082182),\n",
       "             ('10312musaylimah', 0.00382080836877891),\n",
       "             ('103738وما', 0.00382080836877891),\n",
       "             ('1038', 0.00382080836877891),\n",
       "             ('104', 0.025144982563328925),\n",
       "             ('1041', 0.014124635331576613),\n",
       "             ('104let', 0.00780711402560617),\n",
       "             ('105', 0.02232274154804721),\n",
       "             ('1057ibn', 0.010955097259396529),\n",
       "             ('1059', 0.02281655148629709),\n",
       "             ('105لا', 0.009511538943822635),\n",
       "             ('106', 0.02179616596901779),\n",
       "             ('1062the', 0.015174644289929642),\n",
       "             ('10634', 0.004960347706835778),\n",
       "             ('106970', 0.02453527357472077),\n",
       "             ('106970نمتعهم', 0.018895833219500488),\n",
       "             ('106970ومن', 0.0014966501013591114),\n",
       "             ('107', 0.021932011296852273),\n",
       "             ('1072', 0.006413001285619347),\n",
       "             ('10747this', 0.006029726929168245),\n",
       "             ('108', 0.02248192040980273),\n",
       "             ('1082', 0.006413001285619347),\n",
       "             ('108486', 0.006413001285619347),\n",
       "             ('109', 0.043352813630683745),\n",
       "             ('1094', 0.02854584713981936),\n",
       "             ('1096', 0.03155722046363478),\n",
       "             ('109697', 0.014981188595709958),\n",
       "             ('109697about', 0.030791268510633935),\n",
       "             ('1098', 0.01711896082434207),\n",
       "             ('1099', 0.013713238185996712),\n",
       "             ('10th', 0.028636574777384155),\n",
       "             ('11', 0.019825165800444907),\n",
       "             ('110', 0.04496384081960546),\n",
       "             ('110allah', 0.008770363670727366),\n",
       "             ('110he', 0.006029726929168245),\n",
       "             ('111', 0.03258400177577859),\n",
       "             ('11100101', 0.019467331819942382),\n",
       "             ('11102', 0.0014966501013591114),\n",
       "             ('11105addahhak', 0.01589724639897391),\n",
       "             ('11118119', 0.013713238185996712),\n",
       "             ('11121122', 0.011553893931760012),\n",
       "             ('111213th', 0.02680603252858883),\n",
       "             ('11123', 0.01444875014394212),\n",
       "             ('11123قل', 0.007948623199486955),\n",
       "             ('1112ali', 0.030791268510633935),\n",
       "             ('1113', 0.00382080836877891),\n",
       "             ('1113أم', 0.00382080836877891),\n",
       "             ('1117', 0.008757432777510071),\n",
       "             ('1117as', 0.008133611239838941),\n",
       "             ('111so', 0.00382080836877891),\n",
       "             ('112', 0.03219053270989607),\n",
       "             ('1124', 0.01951692711750951),\n",
       "             ('1127', 0.005737843571687616),\n",
       "             ('112also', 0.003949564952173469),\n",
       "             ('112in', 0.007534944422693434),\n",
       "             ('113', 0.07223433847817382),\n",
       "             ('114', 0.07391900103753914),\n",
       "             ('114and', 0.003949564952173469),\n",
       "             ('115', 0.022299586905179403),\n",
       "             ('115356', 0.006354752502654743),\n",
       "             ('116', 0.021325545636214166),\n",
       "             ('1165', 0.003961274976416516),\n",
       "             ('116وتصريف', 0.014286038993672501),\n",
       "             ('117', 0.0218384506111506),\n",
       "             ('1171', 0.004522542839480566),\n",
       "             ('1171also', 0.006584911576492594),\n",
       "             ('117273', 0.004522542839480566),\n",
       "             ('1179', 0.027236404610469847),\n",
       "             ('118', 0.022547134553880844),\n",
       "             ('118283', 0.030605856727229),\n",
       "             ('1188', 0.013242173931504364),\n",
       "             ('1188therefore', 0.013242173931504364),\n",
       "             ('119', 0.022804081158336532),\n",
       "             ('1194', 0.022509379014464724),\n",
       "             ('12', 0.032262853975520395),\n",
       "             ('120', 0.022804081158336532),\n",
       "             ('121', 0.023355007053159217),\n",
       "             ('12100', 0.006181459663709678),\n",
       "             ('12100the', 0.01757064075676064),\n",
       "             ('12101', 0.006413001285619347),\n",
       "             ('12105106allah', 0.013160323775464193),\n",
       "             ('12108islam', 0.008841712257637944),\n",
       "             ('12109', 0.01136859392676766),\n",
       "             ('1217further', 0.007801969634920776),\n",
       "             ('122', 0.023355007053159217),\n",
       "             ('123', 0.008121066231449056),\n",
       "             ('123124also', 0.017412129633672804),\n",
       "             ('124', 0.008375411741210053),\n",
       "             ('125', 0.008516569783407618),\n",
       "             ('125andوننزل', 0.003202554587423099),\n",
       "             ('125the', 0.014733340459261604),\n",
       "             ('126', 0.007896717592103563),\n",
       "             ('127', 0.01460827629280823),\n",
       "             ('128', 0.014379064095177162),\n",
       "             ('129', 0.014854482180362123),\n",
       "             ('1298', 0.023468522549732907),\n",
       "             ('129allah', 0.0014966501013591114),\n",
       "             ('13', 0.040644869959356573),\n",
       "             ('130', 0.030903934924222942),\n",
       "             ('131', 0.02970894279556283),\n",
       "             ('1310', 0.0069408527427894905),\n",
       "             ('1311', 0.0069408527427894905),\n",
       "             ('1315', 0.014097819958393766),\n",
       "             ('1319', 0.004979476853350695),\n",
       "             ('131921', 0.004835127202835852),\n",
       "             ('132', 0.005735094908084932),\n",
       "             ('1320the', 0.007551192039512609),\n",
       "             ('1321الذين', 0.005737843571687616),\n",
       "             ('1325also', 0.004835127202835852),\n",
       "             ('1325the', 0.004835127202835852),\n",
       "             ('133', 0.005735094908084932),\n",
       "             ('1334وأما', 0.006593816016180359),\n",
       "             ('1338', 0.01577532145731522),\n",
       "             ('134', 0.005604388330203141),\n",
       "             ('1340', 0.035105092032380845),\n",
       "             ('1340فذكر', 0.03603978018858291),\n",
       "             ('135', 0.006038699927721724),\n",
       "             ('136', 0.020224758376861333),\n",
       "             ('137', 0.019372788485300798),\n",
       "             ('138', 0.017961261323480002),\n",
       "             ('139', 0.017716994597668255),\n",
       "             ('139these', 0.004751311845086585),\n",
       "             ('14', 0.039611923727417106),\n",
       "             ('140', 0.07026740230261645),\n",
       "             ('141', 0.07226372494086025),\n",
       "             ('1418', 0.006957948439200302),\n",
       "             ('141الم', 0.01153272966034653),\n",
       "             ('142', 0.034349986449589885),\n",
       "             ('1422allah', 0.006957948439200302),\n",
       "             ('142427', 0.004835127202835852),\n",
       "             ('1427', 0.007068495482240984),\n",
       "             ('1428', 0.014238695935449462),\n",
       "             ('142829abu', 0.01464896377180275),\n",
       "             ('1428ibn', 0.012606233981066722),\n",
       "             ('143', 0.009995608066162415),\n",
       "             ('1431', 0.011352841692318214),\n",
       "             ('1434', 0.008285054322620512),\n",
       "             ('1435', 0.0014966501013591114),\n",
       "             ('1437', 0.0014966501013591114),\n",
       "             ('1439allah', 0.0014966501013591114),\n",
       "             ('144', 0.019853661892882228),\n",
       "             ('1440ربنا', 0.007773285923027685),\n",
       "             ('144allah', 0.015342470814166478),\n",
       "             ('145', 0.01955761363078328),\n",
       "             ('145addahhak', 0.005900466337851713),\n",
       "             ('146', 0.013399685116558285),\n",
       "             ('146so', 0.01257952585822548),\n",
       "             ('146we', 0.01257952585822548),\n",
       "             ('147', 0.013399685116558285),\n",
       "             ('148', 0.017448774460854275),\n",
       "             ('149', 0.017174993224794943),\n",
       "             ('15', 0.08128973991871315),\n",
       "             ('150', 0.011132009847286566),\n",
       "             ('151', 0.011480655781032056),\n",
       "             ('151415', 0.010467842364316329),\n",
       "             ('152', 0.017730206306997086),\n",
       "             ('152829', 0.029919817515049955),\n",
       "             ('153', 0.018029028775358866),\n",
       "             ('153031', 0.004522542839480566),\n",
       "             ('154', 0.053186105626477416),\n",
       "             ('154950', 0.010620026565095197),\n",
       "             ('155', 0.004873984563793159),\n",
       "             ('156', 0.004801306048998598),\n",
       "             ('157', 0.006095913088237079),\n",
       "             ('1571', 0.027236404610469847),\n",
       "             ('158', 0.00877439488453929),\n",
       "             ('159', 0.021480708475929384),\n",
       "             ('159293', 0.023405908904762327),\n",
       "             ('159799', 0.007948623199486955),\n",
       "             ('16', 0.007425970080914874),\n",
       "             ('160', 0.04318517433181636),\n",
       "             ('161', 0.04208766896038067),\n",
       "             ('16112the', 0.011770529442980512),\n",
       "             ('16116', 0.02977934888821874),\n",
       "             ('1612', 0.009511538943822635),\n",
       "             ('16120122this', 0.006584911576492594),\n",
       "             ('16120123', 0.006413001285619347),\n",
       "             ('16120123قل', 0.007524319469976976),\n",
       "             ('16121', 0.012585320065854347),\n",
       "             ('16123', 0.008457865468009949),\n",
       "             ('16126allahs', 0.022413432202086893),\n",
       "             ('16126ikrimah', 0.004642181848859226),\n",
       "             ('1615', 0.028249270663153227),\n",
       "             ('162', 0.04208766896038067),\n",
       "             ('1625', 0.006015740835949774),\n",
       "             ('1625وقالت', 0.012473815556895853),\n",
       "             ('163', 0.01724341949262281),\n",
       "             ('1636', 0.003541822446663452),\n",
       "             ('1636this', 0.0134101507678448),\n",
       "             ('164', 0.016972934480973825),\n",
       "             ('1640', 0.007534944422693434),\n",
       "             ('164547', 0.010918934771260436),\n",
       "             ('1648', 0.014231370611160315),\n",
       "             ('1648قالتآ', 0.009864698776346175),\n",
       "             ('165', 0.016972934480973825),\n",
       "             ('1657', 0.01812286089483026),\n",
       "             ('166', 0.016719842241218644),\n",
       "             ('1660similarly', 0.03029355206674707),\n",
       "             ('1666', 0.006762569709661078),\n",
       "             ('1667', 0.011995022636530154),\n",
       "             ('166869', 0.011202898500155522),\n",
       "             ('167', 0.026649037358395623),\n",
       "             ('1675', 0.004835127202835852),\n",
       "             ('1676', 0.004835127202835852),\n",
       "             ('168', 0.0074238392669782605),\n",
       "             ('1680', 0.006762569709661078),\n",
       "             ('1688', 0.024637079689138697),\n",
       "             ('169', 0.007111109323935456),\n",
       "             ('17', 0.007524095709354575),\n",
       "             ('170', 0.007111109323935456),\n",
       "             ('171', 0.03664917324827049),\n",
       "             ('17102', 0.012113193261867043),\n",
       "             ('17107', 0.004277763836514716),\n",
       "             ('17107108these', 0.008133611239838941),\n",
       "             ('17110', 0.003949564952173469),\n",
       "             ('17110also', 0.003949564952173469),\n",
       "             ('17110only', 0.003949564952173469),\n",
       "             ('1715', 0.016689306048181057),\n",
       "             ('1716', 0.006015740835949774),\n",
       "             ('171819in', 0.004994656213830934),\n",
       "             ('172', 0.006607783652898208),\n",
       "             ('1720this', 0.0014966501013591114),\n",
       "             ('1721', 0.011922934799230433),\n",
       "             ('1723', 0.004567335542371097),\n",
       "             ('1726', 0.0134101507678448),\n",
       "             ('173', 0.0064166948850294964),\n",
       "             ('1731', 0.009758463558754754),\n",
       "             ('1732', 0.004862643890068491),\n",
       "             ('1737', 0.0123359260537787),\n",
       "             ('174', 0.006509251559558404),\n",
       "             ('1744والنجم', 0.009864698776346175),\n",
       "             ('175', 0.004992458748841633),\n",
       "             ('1755in', 0.018019890094291453),\n",
       "             ('1757', 0.009463742265712975),\n",
       "             ('1759', 0.0036837069266587477),\n",
       "             ('176', 0.005235596178324355),\n",
       "             ('176365', 0.03391979311866626),\n",
       "             ('176669', 0.00639847580139371),\n",
       "             ('1767', 0.012033660389350408),\n",
       "             ('1767هو', 0.00639847580139371),\n",
       "             ('1768', 0.00382080836877891),\n",
       "             ('177', 0.005542814286600106),\n",
       "             ('1779', 0.020688279460217514),\n",
       "             ('178', 0.039023579971083196),\n",
       "             ('1782', 0.011139842786270969),\n",
       "             ('1782allah', 0.007102316034787591),\n",
       "             ('1782certainly', 0.003202554587423099),\n",
       "             ('1782this', 0.010955097259396529),\n",
       "             ('1788therefore', 0.00382080836877891),\n",
       "             ('1788قل', 0.00382080836877891),\n",
       "             ('179', 0.011716522800034665),\n",
       "             ('1790', 0.011529196514723157),\n",
       "             ('179093', 0.014383222932404969),\n",
       "             ('1790قل', 0.009860129376318753),\n",
       "             ('1792قالوا', 0.028831824150866322),\n",
       "             ('179495', 0.010490346652089092),\n",
       "             ('1795', 0.010467842364316329),\n",
       "             ('17ربكم', 0.00639847580139371),\n",
       "             ('18', 0.02188079954323046),\n",
       "             ('180', 0.015743658930595067),\n",
       "             ('181', 0.04697984384868268),\n",
       "             ('18105', 0.013049530121060278),\n",
       "             ('18110ومآ', 0.002981979112299486),\n",
       "             ('1817andمن', 0.004871736799685554),\n",
       "             ('1817huda', 0.010955097259396529),\n",
       "             ('181وأنه', 0.007948623199486955),\n",
       "             ('182', 0.0411614208761434),\n",
       "             ('1829', 0.01577532145731522),\n",
       "             ('183', 0.04207759927316797),\n",
       "             ('184', 0.014338699562521755),\n",
       "             ('1847', 0.0069408527427894905),\n",
       "             ('1848', 0.007068495482240984),\n",
       "             ('1849', 0.005313464057266952),\n",
       "             ('185', 0.006815264333691972),\n",
       "             ('1850', 0.06597262450091584),\n",
       "             ('1850qatadah', 0.019660715910868962),\n",
       "             ('1850similarly', 0.01757064075676064),\n",
       "             ('186', 0.007464920108540211),\n",
       "             ('186ali', 0.011036312648852093),\n",
       "             ('187', 0.012333433139355535),\n",
       "             ('188', 0.012333433139355535),\n",
       "             ('189', 0.012333433139355535),\n",
       "             ('19', 0.01785206295475405),\n",
       "             ('190', 0.005939226349757202),\n",
       "             ('191', 0.005710466554532666),\n",
       "             ('1910allah', 0.011472961059865614),\n",
       "             ('192', 0.005939226349757202),\n",
       "             ('193', 0.005939226349757202),\n",
       "             ('1931', 0.01172458653085137),\n",
       "             ('194', 0.006386748236756866),\n",
       "             ('194148', 0.005415147175207684),\n",
       "             ('1944', 0.01757064075676064),\n",
       "             ('1949', 0.004522542839480566),\n",
       "             ('195', 0.015791319694368155),\n",
       "             ('1958', 0.004522542839480566),\n",
       "             ('1959', 0.009691001942762685),\n",
       "             ('196', 0.018149533716777376),\n",
       "             ('1964', 0.004751311845086585),\n",
       "             ('197', 0.018149533716777376),\n",
       "             ('1973', 0.005737843571687616),\n",
       "             ('1974', 0.005737843571687616),\n",
       "             ('1975', 0.008048225260157615),\n",
       "             ('197allah', 0.020688279460217514),\n",
       "             ('198', 0.018149533716777376),\n",
       "             ('1981', 0.006957948439200302),\n",
       "             ('198889', 0.05564036239640869),\n",
       "             ('198895', 0.007534944422693434),\n",
       "             ('199', 0.0040705000955552195),\n",
       "             ('199395', 0.004751311845086585),\n",
       "             ('1997hence', 0.005670543972117488),\n",
       "             ('1998', 0.02734052290168358),\n",
       "             ('2', 0.0071471623293017025),\n",
       "             ('20', 0.018010806446326952),\n",
       "             ('200', 0.0037783782597424214),\n",
       "             ('201', 0.008996583013743066),\n",
       "             ('20111', 0.004751311845086585),\n",
       "             ('20112', 0.01444875014394212),\n",
       "             ('20116', 0.003129110396493127),\n",
       "             ('20120', 0.028249270663153227),\n",
       "             ('20123', 0.03354540228860128),\n",
       "             ('20123ibn', 0.030448903615807314),\n",
       "             ('20124', 0.030448903615807314),\n",
       "             ('20126', 0.018102244527690325),\n",
       "             ('20128أولم', 0.02734052290168358),\n",
       "             ('2012allah', 0.030791268510633935),\n",
       "             ('202', 0.008996583013743066),\n",
       "             ('203', 0.014318287388692078),\n",
       "             ('204', 0.005670543972117488),\n",
       "             ('205', 0.005670543972117488),\n",
       "             ('2050', 0.0063552914877735055),\n",
       "             ('2052', 0.018102244527690325),\n",
       "             ('2055', 0.03354540228860128),\n",
       "             ('205860', 0.04788335649260021),\n",
       "             ('205allah', 0.003949564952173469),\n",
       "             ('206', 0.005670543972117488),\n",
       "             ('2065', 0.03317059332448283),\n",
       "             ('206769', 0.03317059332448283),\n",
       "             ('207', 0.005670543972117488),\n",
       "             ('2071', 0.020673183166919757),\n",
       "             ('207275', 0.010336591583459879),\n",
       "             ('207also', 0.005506680441160473),\n",
       "             ('2080', 0.05034128026341739),\n",
       "             ('2085', 0.023561651607469945),\n",
       "             ('2089', 0.023561651607469945),\n",
       "             ('208o', 0.023103253716274034),\n",
       "             ('209', 0.023103253716274034),\n",
       "             ('2090', 0.015502705496298763),\n",
       "             ('209294', 0.015502705496298763),\n",
       "             ('21', 0.019290473317012953),\n",
       "             ('210', 0.02977934888821874),\n",
       "             ('2102', 0.003129110396493127),\n",
       "             ('2104also', 0.01234415011451648),\n",
       "             ('2105', 0.01234415011451648),\n",
       "             ('2105ما', 0.01234415011451648),\n",
       "             ('2109in', 0.021055092925824206),\n",
       "             ('2109the', 0.007162287340268306),\n",
       "             ('211', 0.014238695935449462),\n",
       "             ('21105', 0.011553893931760012),\n",
       "             ('2114', 0.009100432300129973),\n",
       "             ('2115', 0.015030808799029837),\n",
       "             ('2115andليس', 0.003202554587423099),\n",
       "             ('2115andوما', 0.016692108718922606),\n",
       "             ('2116117', 0.007534944422693434),\n",
       "             ('2116allah', 0.011746058487797601),\n",
       "             ('2117', 0.004522542839480566),\n",
       "             ('212', 0.014238695935449462),\n",
       "             ('2121', 0.003909733848210689),\n",
       "             ('2123', 0.02466686627871107),\n",
       "             ('2124', 0.015382218147881934),\n",
       "             ('2125', 0.0033681698775473354),\n",
       "             ('2125there', 0.017514856062190047),\n",
       "             ('2125ولقد', 0.018157603073646562),\n",
       "             ('2126', 0.0014966501013591114),\n",
       "             ('2127', 0.0014966501013591114),\n",
       "             ('2128allahs', 0.00382080836877891),\n",
       "             ('2128these', 0.004751311845086585),\n",
       "             ('2129', 0.018157603073646562),\n",
       "             ('212some', 0.010955097259396529),\n",
       "             ('212الم', 0.01153272966034653),\n",
       "             ('213', 0.011990550686560663),\n",
       "             ('2130', 0.005777796077974146),\n",
       "             ('2130132', 0.006584911576492594),\n",
       "             ('2130فأخرجنا', 0.011995022636530154),\n",
       "             ('2131', 0.007524319469976976),\n",
       "             ('2132وأنزل', 0.0055028139064712015),\n",
       "             ('2133', 0.004522542839480566),\n",
       "             ('2135', 0.01257952585822548),\n",
       "             ('2135allah', 0.01600799581509273),\n",
       "             ('2136', 0.006015740835949774),\n",
       "             ('214', 0.01367026145084179),\n",
       "             ('2140', 0.014124635331576613),\n",
       "             ('2141', 0.006015740835949774),\n",
       "             ('2142allah', 0.016692108718922606),\n",
       "             ('2143', 0.014868037191133276),\n",
       "             ('2143albukhari', 0.003202554587423099),\n",
       "             ('2143the', 0.003202554587423099),\n",
       "             ('2143إن', 0.011553893931760012),\n",
       "             ('2144', 0.014204632069575182),\n",
       "             ('2144a', 0.003202554587423099),\n",
       "             ('2144allah', 0.014204632069575182),\n",
       "             ('2144the', 0.015030808799029837),\n",
       "             ('2146', 0.01686800058262053),\n",
       "             ('2148', 0.04066026482814481),\n",
       "             ('215', 0.045963777631815875),\n",
       "             ('215152', 0.005415147175207684),\n",
       "             ('2155therefore', 0.007162287340268306),\n",
       "             ('2156', 0.005681852827830073),\n",
       "             ('2158', 0.01051907348787826),\n",
       "             ('2159', 0.012982561199321617),\n",
       "             ('216', 0.029365746820326808),\n",
       "             ('2166167', 0.011400652481757218),\n",
       "             ('2167', 0.006957948439200302),\n",
       "             ('2169', 0.023103253716274034),\n",
       "             ('217', 0.005406558978593919),\n",
       "             ('2170', 0.03029355206674707),\n",
       "             ('2171', 0.02343304560006933),\n",
       "             ('21718', 0.009860129376318753),\n",
       "             ('2172', 0.006584911576492594),\n",
       "             ('2174', 0.011770529442980512),\n",
       "             ('2176ذلك', 0.011770529442980512),\n",
       "             ('2177', 0.007850881773237247),\n",
       "             ('218', 0.013680034219444663),\n",
       "             ('2180', 0.008470545925982977),\n",
       "             ('2184', 0.009979052445516683),\n",
       "             ('2185', 0.019958104891033366),\n",
       "             ('2185as', 0.009979052445516683),\n",
       "             ('2187', 0.0030716713381068236),\n",
       "             ('2187further', 0.007948623199486955),\n",
       "             ('2187whatever', 0.005900466337851713),\n",
       "             ('2188', 0.023579930532307027),\n",
       "             ('2189', 0.02210104987174422),\n",
       "             ('219', 0.005809722314170671),\n",
       "             ('2191ومريم', 0.006552687307015074),\n",
       "             ('2194', 0.022413432202086893),\n",
       "             ('2194similarly', 0.004642181848859226),\n",
       "             ('2194the', 0.011036312648852093),\n",
       "             ('2195', 0.013262568386456914),\n",
       "             ('2195abu', 0.014682873410163404),\n",
       "             ('2196', 0.0035978453279583615),\n",
       "             ('2197', 0.005900466337851713),\n",
       "             ('219899the', 0.00382080836877891),\n",
       "             ('2198allah', 0.020688279460217514),\n",
       "             ('2199', 0.014318287388692078),\n",
       "             ('219it', 0.009864698776346175),\n",
       "             ('21allah', 0.005245192541873757),\n",
       "             ('21حتى', 0.001432110601999585),\n",
       "             ('22', 0.017944626341407397),\n",
       "             ('220', 0.005309892936708841),\n",
       "             ('2200', 0.006955045299551086),\n",
       "             ('2204', 0.005670543972117488),\n",
       "             ('2207', 0.011341087944234976),\n",
       "             ('221', 0.012840083629940468),\n",
       "             ('2211', 0.004155028834907226),\n",
       "             ('22122', 0.0055028139064712015),\n",
       "             ('2214', 0.009012194458310363),\n",
       "             ('2215', 0.045963777631815875),\n",
       "             ('2217', 0.027942737062513618),\n",
       "             ('2217إن', 0.006029726929168245),\n",
       "             ('2219then', 0.005809722314170671),\n",
       "             ('222', 0.004341368465053149),\n",
       "             ('2220', 0.01162521426467211),\n",
       "             ('2225', 0.010149634538602438),\n",
       "             ('2225it', 0.005900466337851713),\n",
       "             ('2226', 0.007773285923027685),\n",
       "             ('2228', 0.004441493684651165),\n",
       "             ('2229', 0.004156140878989396),\n",
       "             ('222the', 0.0055028139064712015),\n",
       "             ('223', 0.004072190675756178),\n",
       "             ('2230', 0.032101443935401396),\n",
       "             ('2232', 0.05034128026341739),\n",
       "             ('2232it', 0.01678042675447246),\n",
       "             ('2233', 0.007462354486106577),\n",
       "             ('2234', 0.03932613085357758),\n",
       "             ('2234albukhari', 0.006554355142262929),\n",
       "             ('2234ata', 0.006554355142262929),\n",
       "             ('2234for', 0.006554355142262929),\n",
       "             ('2234so', 0.006554355142262929),\n",
       "             ('2236', 0.013108710284525859),\n",
       "             ('2237', 0.003976916413317097),\n",
       "             ('2237abu', 0.007551192039512609),\n",
       "             ('2237allah', 0.007655628906003585),\n",
       "             ('2238', 0.007534944422693434),\n",
       "             ('224', 0.010149634538602438),\n",
       "             ('2240', 0.0031066665913946187),\n",
       "             ('2240allah', 0.016329058186793772),\n",
       "             ('2240ibn', 0.006554355142262929),\n",
       "             ('2241', 0.006554355142262929),\n",
       "             ('2244', 0.007088901044705954),\n",
       "             ('2245', 0.009736265425380919),\n",
       "             ('2246', 0.013139735063720185),\n",
       "             ('2246ومآ', 0.011139842786270969),\n",
       "             ('2247', 0.009970321339396352),\n",
       "             ('2247وكان', 0.01589724639897391),\n",
       "             ('2248also', 0.0014966501013591114),\n",
       "             ('224fuel', 0.00382080836877891),\n",
       "             ('225', 0.00927642834413066),\n",
       "             ('2253', 0.011139842786270969),\n",
       "             ('2254', 0.01172458653085137),\n",
       "             ('2254وما', 0.011139842786270969),\n",
       "             ('2255', 0.020728810373606642),\n",
       "             ('2257', 0.018382465031214944),\n",
       "             ('2258', 0.014124635331576613),\n",
       "             ('2259', 0.013971368531256809),\n",
       "             ('226', 0.009550165749897229),\n",
       "             ('2261we', 0.007088901044705954),\n",
       "             ('22627', 0.004835127202835852),\n",
       "             ('227', 0.01864848997015957),\n",
       "             ('2272', 0.007864797943936864),\n",
       "             ('2272this', 0.005670543972117488),\n",
       "             ('2272من', 0.010955097259396529),\n",
       "             ('2273مثل', 0.004835127202835852),\n",
       "             ('2274', 0.005324067617691407),\n",
       "             ('2275', 0.007102316034787591),\n",
       "             ('2278', 0.006413001285619347),\n",
       "             ('2278moreover', 0.003202554587423099),\n",
       "             ('228', 0.009495510947890107),\n",
       "             ('2283', 0.01957716454688454),\n",
       "             ('2284', 0.029051914411559958),\n",
       "             ('2285', 0.01498635048443142),\n",
       "             ('2286', 0.008933804666465622),\n",
       "             ('228furthermore', 0.004155028834907226),\n",
       "             ('229', 0.004238450212025991),\n",
       "             ('23', 0.017754756599452724),\n",
       "             ('230', 0.010200583799466985),\n",
       "             ('231', 0.018710918327995842),\n",
       "             ('23101', 0.007068495482240984),\n",
       "             ('23101ولا', 0.05156911636740318),\n",
       "             ('232', 0.01678042675447246),\n",
       "             ('233', 0.007660629605302646),\n",
       "             ('234', 0.008971713314272406),\n",
       "             ('2344thereafter', 0.013524523055843478),\n",
       "             ('235', 0.011577569943915258),\n",
       "             ('2351', 0.0076122259039518286),\n",
       "             ('235556', 0.006689271714952144),\n",
       "             ('235556ibn', 0.011036312648852093),\n",
       "             ('2357', 0.005737843571687616),\n",
       "             ('236', 0.058731493640653616),\n",
       "             ('2360', 0.0014966501013591114),\n",
       "             ('237', 0.01832572902803218),\n",
       "             ('2379', 0.014318287388692078),\n",
       "             ('238', 0.0064259049838554395),\n",
       "             ('2388فيومئذ', 0.01172458653085137),\n",
       "             ('239', 0.0064259049838554395),\n",
       "             ('24', 0.02113170411156049),\n",
       "             ('240', 0.006554355142262929),\n",
       "             ('241', 0.006083977986685012),\n",
       "             ('242', 0.006554355142262929),\n",
       "             ('2422continuity', 0.010149634538602438),\n",
       "             ('2425', 0.01589724639897391),\n",
       "             ('243', 0.006580161887732096),\n",
       "             ('2436there', 0.0014966501013591114),\n",
       "             ('2439', 0.005432484892951145),\n",
       "             ('2439allah', 0.004155028834907226),\n",
       "             ('2439this', 0.006957948439200302),\n",
       "             ('244', 0.006386748236756866),\n",
       "             ('2440', 0.009860129376318753),\n",
       "             ('2440the', 0.004155028834907226),\n",
       "             ('2440therefore', 0.004155028834907226),\n",
       "             ('2440this', 0.009864698776346175),\n",
       "             ('245', 0.007088901044705954),\n",
       "             ('2455therefore', 0.006593816016180359),\n",
       "             ('245there', 0.01462447341153307),\n",
       "             ('246', 0.021722607236954076),\n",
       "             ('2461', 0.005305027354582765),\n",
       "             ('2469', 0.01464896377180275),\n",
       "             ('247', 0.03109314369211074),\n",
       "             ('248', 0.030791268510633935),\n",
       "             ('248ولا', 0.01172458653085137),\n",
       "             ('249', 0.026102886062512723),\n",
       "             ('25', 0.0228272102835963),\n",
       "             ('250', 0.016329058186793772),\n",
       "             ('251', 0.009265704990322404),\n",
       "             ('251the', 0.008841712257637944),\n",
       "             ('252', 0.016329058186793772),\n",
       "             ('2520', 0.014548168149519704),\n",
       "             ('2520ومآ', 0.002981979112299486),\n",
       "             ('2521', 0.005498187012478659),\n",
       "             ('2522', 0.010467842364316329),\n",
       "             ('2523allah', 0.006957948439200302),\n",
       "             ('2523والذين', 0.006029726929168245),\n",
       "             ('2525', 0.02977934888821874),\n",
       "             ('2526', 0.0123359260537787),\n",
       "             ('253', 0.018019890094291453),\n",
       "             ('2531', 0.005498187012478659),\n",
       "             ('254', 0.02052515461570654),\n",
       "             ('2541', 0.006015740835949774),\n",
       "             ('2545', 0.011139842786270969),\n",
       "             ('255', 0.006362448347557033),\n",
       "             ('25556', 0.011529196514723157),\n",
       "             ('2559', 0.003949564952173469),\n",
       "             ('255allahs', 0.014383222932404969),\n",
       "             ('256', 0.011681402050074754),\n",
       "             ('2561', 0.011856077220916993),\n",
       "             ('2568', 0.004879231779377377),\n",
       "             ('257', 0.04257047861201739),\n",
       "             ('2571the', 0.02734052290168358),\n",
       "             ('2574this', 0.0014966501013591114),\n",
       "             ('258', 0.01577861023181739),\n",
       "             ('259', 0.013971368531256809),\n",
       "             ('25these', 0.030791268510633935),\n",
       "             ('26', 0.05117469302598863),\n",
       "             ('260', 0.014548168149519704),\n",
       "             ('261', 0.019153342597040084),\n",
       "             ('26100101allahs', 0.01172458653085137),\n",
       "             ('26111', 0.005737843571687616),\n",
       "             ('26112113', 0.005737843571687616),\n",
       "             ('26128131', 0.0072434027341418536),\n",
       "             ('26155', 0.003961274976416516),\n",
       "             ('26187', 0.022509379014464724),\n",
       "             ('26189', 0.04501875802892945),\n",
       "             ('26192194albukhari', 0.007102316034787591),\n",
       "             ('26193194albukhari', 0.013524523055843478),\n",
       "             ('262', 0.031031887719067935),\n",
       "             ('26205207there', 0.00382080836877891),\n",
       "             ('262324', 0.010181382525185538),\n",
       "             ('263', 0.007464920108540211),\n",
       "             ('264', 0.008883487512557109),\n",
       "             ('265', 0.023655522729412057),\n",
       "             ('266', 0.017817419419074693),\n",
       "             ('267', 0.012412918421116616),\n",
       "             ('267o', 0.007655628906003585),\n",
       "             ('268', 0.007655628906003585),\n",
       "             ('2688', 0.04712330321493989),\n",
       "             ('269', 0.007655628906003585),\n",
       "             ('269293', 0.007068495482240984),\n",
       "             ('27', 0.04489351355773939),\n",
       "             ('270', 0.018382465031214944),\n",
       "             ('271', 0.018382465031214944),\n",
       "             ('2712', 0.0326238253026507),\n",
       "             ('2714بل', 0.012113193261867043),\n",
       "             ('272', 0.006062075249603697),\n",
       "             ('272526they', 0.005506680441160473),\n",
       "             ('2728whoever', 0.0055028139064712015),\n",
       "             ('273', 0.006062075249603697),\n",
       "             ('274', 0.005461629125209467),\n",
       "             ('274950', 0.003961274976416516),\n",
       "             ('275', 0.0068647200359205525),\n",
       "             ('276', 0.01777705450623481),\n",
       "             ('2762', 0.011922934799230433),\n",
       "             ('2762ولو', 0.00906143044741513),\n",
       "             ('2763', 0.00639847580139371),\n",
       "             ('277', 0.01777705450623481),\n",
       "             ('278', 0.00568241945687585),\n",
       "             ('279', 0.00568241945687585),\n",
       "             ('28', 0.004293895015615675),\n",
       "             ('280', 0.00568241945687585),\n",
       "             ('281', 0.00568241945687585),\n",
       "             ('282', 0.004702002456034537),\n",
       "             ('2823', 0.03219797620908929),\n",
       "             ('2824also', 0.007948623199486955),\n",
       "             ('283', 0.004567335542371097),\n",
       "             ('2838what', 0.01577861023181739),\n",
       "             ('284', 0.009683971470519985),\n",
       "             ('2843', 0.03791848411161507),\n",
       "             ('2848', 0.030764436295763867),\n",
       "             ('28485', 0.0033175890385382534),\n",
       "             ('2849قل', 0.00382080836877891),\n",
       "             ('285', 0.007262023306723194),\n",
       "             ('285254', 0.003909733848210689),\n",
       "             ('2856', 0.027745496285431895),\n",
       "             ('2856ليس', 0.010955097259396529),\n",
       "             ('286', 0.05963418221226853),\n",
       "             ('2860', 0.007162287340268306),\n",
       "             ('2861', 0.002981979112299486),\n",
       "             ('2861after', 0.018895833219500488),\n",
       "             ('2862', 0.0059008416096079765),\n",
       "             ('2863', 0.006957948439200302),\n",
       "             ('2864', 0.007068495482240984),\n",
       "             ('2865', 0.010918934771260436),\n",
       "             ('2869', 0.012997953510636458),\n",
       "             ('287', 0.011202898500155522),\n",
       "             ('287when', 0.011472961059865614),\n",
       "             ('2880', 0.003129110396493127),\n",
       "             ('2880also', 0.012526447690047312),\n",
       "             ('2886', 0.005995569310595079),\n",
       "             ('28muhammad', 0.009928990309502384),\n",
       "             ('29', 0.004544900135204213),\n",
       "             ('2912', 0.009012194458310363),\n",
       "             ('2913', 0.011400652481757218),\n",
       "             ('2913the', 0.01367026145084179),\n",
       "             ('2925', 0.010413249899308193),\n",
       "             ('2927', 0.006584911576492594),\n",
       "             ('2927وجعلنا', 0.007524319469976976),\n",
       "             ('2927ولقد', 0.004522542839480566),\n",
       "             ('2940', 0.00382080836877891),\n",
       "             ('2941', 0.004835127202835852),\n",
       "             ('2943', 0.017817419419074693),\n",
       "             ('2945the', 0.012526447690047312),\n",
       "             ('2946يـأيهآ', 0.015066511432756748),\n",
       "             ('2948', 0.0035978453279583615),\n",
       "             ('2948also', 0.015382218147881934),\n",
       "             ('2960', 0.009860129376318753),\n",
       "             ('2967', 0.004960347706835778),\n",
       "             ('2967we', 0.0014966501013591114),\n",
       "             ('2969', 0.005737843571687616),\n",
       "             ('297allahs', 0.008457865468009949),\n",
       "             ('299', 0.004702002456034537),\n",
       "             ('29then', 0.014238695935449462),\n",
       "             ('2then', 0.04917055281543094),\n",
       "             ('3', 0.0036327176647696475),\n",
       "             ('30', 0.0046025978791722115),\n",
       "             ('3025', 0.004751311845086585),\n",
       "             ('3028mujahid', 0.004835127202835852),\n",
       "             ('3030', 0.007387670101395903),\n",
       "             ('3039ibn', 0.01777705450623481),\n",
       "             ('3046', 0.011995022636530154),\n",
       "             ('3050', 0.011995022636530154),\n",
       "             ('31', 0.00915510563308971),\n",
       "             ('3100', 0.021055092925824206),\n",
       "             ('3101', 0.021055092925824206),\n",
       "             ('3102', 0.018819449144476787),\n",
       "             ('3103this', 0.009409724572238393),\n",
       "             ('3105', 0.00780711402560617),\n",
       "             ('3106', 0.00780711402560617),\n",
       "             ('310إن', 0.020688279460217514),\n",
       "             ('3110', 0.014218455671571447),\n",
       "             ('3110also', 0.02844395207708785),\n",
       "             ('3111this', 0.004934370421511481),\n",
       "             ('3112', 0.009409724572238393),\n",
       "             ('3113', 0.014502103546140236),\n",
       "             ('3113abu', 0.006584911576492594),\n",
       "             ('3113وإن', 0.032865291778189594),\n",
       "             ('3114', 0.0134101507678448),\n",
       "             ('311415', 0.004879231779377377),\n",
       "             ('3116', 0.013494400466096422),\n",
       "             ('3117', 0.011946216456771026),\n",
       "             ('3118', 0.009624964450818818),\n",
       "             ('312', 0.004751311845086585),\n",
       "             ('3120', 0.009624964450818818),\n",
       "             ('3121', 0.007814459381231875),\n",
       "             ('3122', 0.01562891876246375),\n",
       "             ('3123', 0.01783043905430158),\n",
       "             ('312324', 0.022424423889737338),\n",
       "             ('3123this', 0.014733340459261604),\n",
       "             ('3124', 0.058933361837046415),\n",
       "             ('3124125the', 0.014733340459261604),\n",
       "             ('3124فمهل', 0.018895833219500488),\n",
       "             ('3125', 0.014733340459261604),\n",
       "             ('3126', 0.002981979112299486),\n",
       "             ('3126this', 0.007864797943936864),\n",
       "             ('3127', 0.007864797943936864),\n",
       "             ('3127ليس', 0.007864797943936864),\n",
       "             ('3128all', 0.007864797943936864),\n",
       "             ('3128meaning', 0.007864797943936864),\n",
       "             ('3129', 0.007864797943936864),\n",
       "             ('312إن', 0.004751311845086585),\n",
       "             ('313', 0.016966528926818755),\n",
       "             ('3131132', 0.005324067617691407),\n",
       "             ('3133', 0.015972202853074224),\n",
       "             ('3134', 0.006324185482728429),\n",
       "             ('3135', 0.005179141536083954),\n",
       "             ('3137', 0.009012194458310363),\n",
       "             ('3139', 0.009012194458310363),\n",
       "             ('3140141', 0.009012194458310363),\n",
       "             ('3140therefore', 0.009012194458310363),\n",
       "             ('3142', 0.009012194458310363),\n",
       "             ('3145', 0.014983968641492802),\n",
       "             ('3146147', 0.004994656213830934),\n",
       "             ('3149', 0.00399724773210555),\n",
       "             ('3152', 0.0079944954642111),\n",
       "             ('3153he', 0.00399724773210555),\n",
       "             ('3154', 0.00835096512669821),\n",
       "             ('3155because', 0.00835096512669821),\n",
       "             ('3157', 0.021983868220352705),\n",
       "             ('3158', 0.021983868220352705),\n",
       "             ('3159', 0.002981979112299486),\n",
       "             ('3162', 0.002981979112299486),\n",
       "             ('3163', 0.002981979112299486),\n",
       "             ('3164', 0.00908431505780945),\n",
       "             ('3164allah', 0.012606233981066722),\n",
       "             ('3167this', 0.010068108685188194),\n",
       "             ('3168', 0.010068108685188194),\n",
       "             ('3168allah', 0.007088901044705954),\n",
       "             ('3171', 0.003319964468902009),\n",
       "             ('3172this', 0.003319964468902009),\n",
       "             ('3173', 0.003319964468902009),\n",
       "             ('3173this', 0.003319964468902009),\n",
       "             ('3175', 0.003319964468902009),\n",
       "             ('3176', 0.006689271714952144),\n",
       "             ('3178', 0.016183692028141527),\n",
       "             ('3178he', 0.011036312648852093),\n",
       "             ('3179', 0.006689271714952144),\n",
       "             ('3180therefore', 0.006689271714952144),\n",
       "             ('3181this', 0.015286508679764608),\n",
       "             ('3185', 0.009876438840908627),\n",
       "             ('3186', 0.007162287340268306),\n",
       "             ('3187', 0.009691001942762685),\n",
       "             ('319', 0.008841712257637944),\n",
       "             ('3190', 0.006386748236756866),\n",
       "             ('3190the', 0.006580161887732096),\n",
       "             ('3191albukhari', 0.006580161887732096),\n",
       "             ('3195', 0.016869684343591998),\n",
       "             ('3196', 0.020688279460217514),\n",
       "             ('3198', 0.018895833219500488),\n",
       "             ('3199', 0.00714222903756585),\n",
       "             ('3199الذين', 0.032865291778189594),\n",
       "             ('32', 0.05588998920361249),\n",
       "             ('320', 0.010626802389760381),\n",
       "             ('3200', 0.008555527673029433),\n",
       "             ('320abu', 0.006029726929168245),\n",
       "             ('320allah', 0.008133611239838941),\n",
       "             ('3212حـم', 0.01153272966034653),\n",
       "             ('3217', 0.00382080836877891),\n",
       "             ('3224', 0.015382218147881934),\n",
       "             ('3226', 0.02734052290168358),\n",
       "             ('329', 0.009683971470519985),\n",
       "             ('33', 0.024591467571865488),\n",
       "             ('331012when', 0.01367026145084179),\n",
       "             ('3321', 0.004862643890068491),\n",
       "             ('3337', 0.007462354486106577),\n",
       "             ('334', 0.007462354486106577),\n",
       "             ('3340', 0.007462354486106577),\n",
       "             ('3343', 0.003949564952173469),\n",
       "             ('3344', 0.01462447341153307),\n",
       "             ('3345', 0.008933804666465622),\n",
       "             ('3349', 0.004248493846745205),\n",
       "             ('336061these', 0.01570049829997671),\n",
       "             ('336668', 0.012473815556895853),\n",
       "             ('337', 0.011995022636530154),\n",
       "             ('3372تسبح', 0.009864698776346175),\n",
       "             ('339', 0.014674945799040637),\n",
       "             ('33fear', 0.007801969634920776),\n",
       "             ('33this', 0.01172458653085137),\n",
       "             ('34', 0.034349986449589885),\n",
       "             ('340', 0.014674945799040637),\n",
       "             ('3415yet', 0.01251085071635225),\n",
       "             ('342021', 0.010775927776919103),\n",
       "             ('342526', 0.01444875014394212),\n",
       "             ('3426', 0.006029726929168245),\n",
       "             ('343133', 0.005313464057266952),\n",
       "             ('343233', 0.012473815556895853),\n",
       "             ('3434', 0.01711896082434207),\n",
       "             ('343435', 0.006015740835949774),\n",
       "             ('3439', 0.014238695935449462),\n",
       "             ('3441', 0.01757064075676064),\n",
       "             ('344the', 0.006957948439200302),\n",
       "             ('349', 0.005415147175207684),\n",
       "             ('35', 0.03290298996709818),\n",
       "             ('350hence', 0.013524523055843478),\n",
       "             ('351', 0.0065391830238780615),\n",
       "             ('3511', 0.004994656213830934),\n",
       "             ('3514', 0.013937878415686448),\n",
       "             ('351517', 0.011553893931760012),\n",
       "             ('3518', 0.011290904218839864),\n",
       "             ('3518لكل', 0.01172458653085137),\n",
       "             ('351923', 0.01951692711750951),\n",
       "             ('352', 0.011286559522605816),\n",
       "             ('3524', 0.024637079689138697),\n",
       "             ('3528', 0.007801969634920776),\n",
       "             ('3536', 0.030605856727229),\n",
       "             ('3542', 0.02019570137783138),\n",
       "             ('355', 0.0069408527427894905),\n",
       "             ('356', 0.005797537978012782),\n",
       "             ('358', 0.008172756899572945),\n",
       "             ('359', 0.007534944422693434),\n",
       "             ('359there', 0.006181459663709678),\n",
       "             ('36', 0.030957573633503065),\n",
       "             ('361when', 0.008048225260157615),\n",
       "             ('3633', 0.010283309787263077),\n",
       "             ('363335', 0.020474262776146297),\n",
       "             ('3634', 0.011995022636530154),\n",
       "             ('3636', 0.009511538943822635),\n",
       "             ('3636allah', 0.014286038993672501),\n",
       "             ('3637', 0.055390726790496524),\n",
       "             ('363738', 0.009511538943822635),\n",
       "             ('363740', 0.011856077220916993),\n",
       "             ('364', 0.013553421609381605),\n",
       "             ('3640', 0.01014338426414287),\n",
       "             ('3640sometimes', 0.014286038993672501),\n",
       "             ('366061', 0.01757064075676064),\n",
       "             ('366062', 0.026877124208434706),\n",
       "             ('367', 0.014124635331576613),\n",
       "             ('3670', 0.008172756899572945),\n",
       "             ('367172', 0.006762569709661078),\n",
       "             ('36768', 0.006584911576492594),\n",
       "             ('36768allah', 0.007524319469976976),\n",
       "             ('3682إنما', 0.007534944422693434),\n",
       "             ('37', 0.01736750061857157),\n",
       "             ('37147', 0.008641258887446554),\n",
       "             ('37147148', 0.01711896082434207),\n",
       "             ('37161163', 0.01677270114430064),\n",
       "             ('37171173', 0.008172756899572945),\n",
       "             ('3723', 0.012585320065854347),\n",
       "             ('372426', 0.01172458653085137),\n",
       "             ('3725', 0.01172458653085137),\n",
       "             ('372526', 0.01172458653085137),\n",
       "             ('3753', 0.01589724639897391),\n",
       "             ('375559', 0.016222776516618652),\n",
       "             ('3761', 0.02868374978300689),\n",
       "             ('3771', 0.05301371611680737),\n",
       "             ('379', 0.018157603073646562),\n",
       "             ('379596', 0.01757064075676064),\n",
       "             ('37the', 0.01153272966034653),\n",
       "             ('37وما', 0.006181459663709678),\n",
       "             ('38', 0.008596028391983394),\n",
       "             ('381', 0.026506858058403686),\n",
       "             ('383indeed', 0.017514856062190047),\n",
       "             ('385in', 0.008841712257637944),\n",
       "             ('385this', 0.015174644289929642),\n",
       "             ('385قال', 0.009970321339396352),\n",
       "             ('3888', 0.01577532145731522),\n",
       "             ('38this', 0.01577861023181739),\n",
       "             ('39', 0.008019480396811628),\n",
       "             ('391', 0.026539754448496194),\n",
       "             ('391إن', 0.01172458653085137),\n",
       "             ('392', 0.007551192039512609),\n",
       "             ('3922', 0.021356906778419497),\n",
       "             ('393', 0.016915730936019897),\n",
       "             ('3937', 0.0123359260537787),\n",
       "             ('3938', 0.003319964468902009),\n",
       "             ('3938he', 0.015187779926426467),\n",
       "             ('394', 0.0042319828658322674),\n",
       "             ('3942the', 0.006593816016180359),\n",
       "             ('395', 0.008457865468009949),\n",
       "             ('3953ibn', 0.014548168149519704),\n",
       "             ('3956', 0.013937878415686448),\n",
       "             ('3958', 0.013937878415686448),\n",
       "             ('395therefore', 0.008457865468009949),\n",
       "             ('396', 0.01717313475100138),\n",
       "             ('3964', 0.009876438840908627),\n",
       "             ('3965', 0.004522542839480566),\n",
       "             ('39697the', 0.007773285923027685),\n",
       "             ('397', 0.017525109522213804),\n",
       "             ('397ibn', 0.004960347706835778),\n",
       "             ('3those', 0.007801969634920776),\n",
       "             ('3كنتم', 0.003319964468902009),\n",
       "             ('4', 0.007122013948257658),\n",
       "             ('40', 0.013163009203042536),\n",
       "             ('4011', 0.04563310297259418),\n",
       "             ('4016', 0.0123359260537787),\n",
       "             ('4019', 0.007417806258164754),\n",
       "             ('403', 0.038676837275552385),\n",
       "             ('4046', 0.009437757532724236),\n",
       "             ('404قل', 0.018895833219500488),\n",
       "             ('4051', 0.030605856727229),\n",
       "             ('405152', 0.009485180410945124),\n",
       "             ('4052further', 0.020688279460217514),\n",
       "             ('4052this', 0.011036312648852093),\n",
       "             ('4060', 0.00490265847661025),\n",
       "             ('4064the', 0.0055028139064712015),\n",
       "             ('407', 0.006686414645363093),\n",
       "             ('407374', 0.011254053700692018),\n",
       "             ('4084', 0.013312861446373152),\n",
       "             ('408485', 0.012364524976979709),\n",
       "             ('40this', 0.006955045299551086),\n",
       "             ('41', 0.013603813932386966),\n",
       "             ('410', 0.005809722314170671),\n",
       "             ('4101', 0.006062075249603697),\n",
       "             ('4102', 0.0064259049838554395),\n",
       "             ('4103we', 0.0064259049838554395),\n",
       "             ('4108this', 0.005670543972117488),\n",
       "             ('410also', 0.011770529442980512),\n",
       "             ('411', 0.013744296771024135),\n",
       "             ('4110', 0.005838288518340047),\n",
       "             ('4111فسواهن', 0.012866128424321685),\n",
       "             ('4111لو', 0.009864698776346175),\n",
       "             ('4112', 0.00913587639952262),\n",
       "             ('4115', 0.009970321339396352),\n",
       "             ('4116', 0.004879231779377377),\n",
       "             ('4117120', 0.01757064075676064),\n",
       "             ('4117in', 0.03624572178966052),\n",
       "             ('4117testifying', 0.010955097259396529),\n",
       "             ('411explaining', 0.007167233122249255),\n",
       "             ('412', 0.013108710284525859),\n",
       "             ('4121it', 0.009864698776346175),\n",
       "             ('4123', 0.005432142724040476),\n",
       "             ('4127', 0.013078366047756123),\n",
       "             ('4129', 0.0065391830238780615),\n",
       "             ('412so', 0.006554355142262929),\n",
       "             ('4130', 0.015174644289929642),\n",
       "             ('4133يأيها', 0.011553893931760012),\n",
       "             ('413435', 0.012526447690047312),\n",
       "             ('4135', 0.01957716454688454),\n",
       "             ('4136', 0.03821085128428067),\n",
       "             ('4136ولا', 0.015066511432756748),\n",
       "             ('4140', 0.014066639291902081),\n",
       "             ('4142', 0.006029726929168245),\n",
       "             ('4142also', 0.009928990309502384),\n",
       "             ('4143', 0.01677270114430064),\n",
       "             ('4144', 0.009550165749897229),\n",
       "             ('4145', 0.009437757532724236),\n",
       "             ('4145since', 0.015342470814166478),\n",
       "             ('4150151albukhari', 0.02249291245812266),\n",
       "             ('4150allah', 0.007102316034787591),\n",
       "             ('4152this', 0.015066511432756748),\n",
       "             ...])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_texts = new_df['Clean_Text'].to_list()\n",
    "\n",
    "\n",
    "def tfidf(docfreq, no_of_docs, no_of_words, method=None):\n",
    "    \n",
    "    tfidf = {}\n",
    "    #total_tokens = len(tokensfreq)\n",
    "\n",
    "    for i in range(len(clean_texts)):\n",
    "        text = clean_texts[i]\n",
    "        total_tokens = len(text)\n",
    "        occurences = Counter(text)\n",
    "    \n",
    "        for token in text:\n",
    "           \n",
    "            if (method==None or method == 'natural'):\n",
    "                tf = occurences[token]/total_tokens\n",
    "            elif method == 'log':\n",
    "                tf = 1 + np.log(occurences[token]/total_tokens)\n",
    "            df = docfreq[token]\n",
    "            idf = np.log(len(clean_texts)/(df+1))\n",
    "            tfidf[token] = tf*idf\n",
    "        \n",
    "\n",
    "    tfidf = collections.OrderedDict(sorted(tfidf.items()))\n",
    "    return tfidf\n",
    "\n",
    "docfreq = {}\n",
    "no_of_docs = len(clean_texts)\n",
    "\n",
    "for t in invertedindex:\n",
    "    docfreq[t] = invertedindex[t][0]\n",
    "    \n",
    "no_of_words = len(docfreq)\n",
    "\n",
    "tfidf = tfidf(docfreq, no_of_docs, no_of_words)\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c3dd086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.05245781428953969,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.01570049829997671,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "wordDict = sorted(docfreq.keys())\n",
    "\n",
    "def computeTFIDFVector(tweet):\n",
    "    tfidfVector = [0.0] * len(wordDict)\n",
    "    \n",
    "    for i, word in enumerate(wordDict):\n",
    "        if word in tweet:\n",
    "            tfidfVector[i] = tfidf[word]\n",
    "    return tfidfVector\n",
    "\n",
    "        \n",
    "\n",
    "if use_loaded_tfidf == 0:\n",
    "    tfidfVector = [computeTFIDFVector(tweet) for tweet in clean_tweets]\n",
    "else:\n",
    "    with open(\"../pickle/tfIDF\", \"rb\") as fp:   # Unpickling\n",
    "       tfidfVector = pickle.load(fp)\n",
    "    \n",
    "\n",
    "tfidfVector[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "067fdf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(vector_x, vector_y):\n",
    "    dot = 0.0\n",
    "    for e_x, e_y in zip(vector_x, vector_y):\n",
    "        dot += e_x * e_y\n",
    "    return dot\n",
    "\n",
    "def magnitude(vector):\n",
    "    mag = 0.0\n",
    "    for index in vector:\n",
    "        mag += math.pow(index, 2)\n",
    "    return math.sqrt(mag)\n",
    "\n",
    "\n",
    "def cosine_score(text1, text2=None):\n",
    "    index_t1 = new_df[\"Original_Text\"].str.contains(text1).idxmax()\n",
    "    \n",
    "    if text2 == None:\n",
    "        \n",
    "        sim_docs=[]\n",
    "        score=[]\n",
    "        doc_cos_pair ={}\n",
    "       \n",
    "        for i in range(len(tfidfVector)):\n",
    "            cosim = dot_product(tfidfVector[index_t1], tfidfVector[i])/ (magnitude(tfidfVector[index_t1]) * magnitude(tfidfVector[i]))\n",
    "            #sim_docs.append(cosim)\n",
    "            \n",
    "            doc_cos_pair[i] = cosim\n",
    "            \n",
    "        for w in sorted(doc_cos_pair, key=doc_cos_pair.get, reverse=True):\n",
    "            sim_docs.append(w)\n",
    "            score.append(doc_cos_pair[w])\n",
    "                \n",
    "            \n",
    "        return(sim_docs[1:], score[1:])\n",
    "            \n",
    "        \n",
    "    else:    \n",
    "        index_t2 = new_df[\"Original_Text\"].str.contains(text2).idxmax()\n",
    "        cosim = dot_product(tfidfVector[index_t1], tfidfVector[index_t2])/ (magnitude(tfidfVector[index_t1]) * magnitude(tfidfVector[index_t2]))\n",
    "    \n",
    "    return cosim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45021f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranking(docids, query_list):\n",
    "    \n",
    "    relevantquery = ' '.join(query_list)\n",
    "    #print(relevantquery)\n",
    "    ranktuple = []\n",
    "    \n",
    "    for i in docids:\n",
    "        score=0\n",
    "        if relevantquery in (new_df['Original_Text'].iloc[i]):\n",
    "            score+=1\n",
    "        \n",
    "        score+=cosine_score(relevantquery, new_df['Original_Text'].iloc[i])\n",
    "        ranktuple.append((i,score))\n",
    "        \n",
    "        \n",
    "    rankedtuple = sorted(ranktuple, key=lambda x: x[1], reverse=True)\n",
    "    rankedverses = [x[0] for x in rankedtuple]\n",
    "    \n",
    "    chapverses_list = []\n",
    "    for docs in rankedverses:\n",
    "        chap = new_df['Chapter'].iloc[docs]\n",
    "        verse = new_df['Verse'].iloc[docs]\n",
    "        chapverses_list.append((chap,verse))\n",
    "        \n",
    "    \n",
    "    return rankedverses, chapverses_list\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8352b6",
   "metadata": {},
   "source": [
    "## Boolean Retrieval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae90b605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boolean_retrieval(query, explanation=0):\n",
    "    print(\"Query :\", query)\n",
    "    \n",
    "    query=query.lower()\n",
    "    tokens = re.findall(r'([A-Za-z]+)',query)\n",
    "    #print(tokens)\n",
    "    \n",
    "\n",
    "    #print(tokens)\n",
    "\n",
    "    accepted_pos = ['VBN','VBG','VB','RP','RBS','RBR','RB','NNS','NNP','NN','JJS','JJR','JJ']\n",
    "\n",
    "    query_words = nltk.pos_tag(tokens)\n",
    "    #print(query_words)\n",
    "\n",
    "    query_list =[]\n",
    "\n",
    "    for i in range(0,len(query_words)):\n",
    "        if (query_words[i][1] in accepted_pos) and (query_words[i][0]!='story') and (query_words[i][0]!='be') and (query_words[i][0]!='i') :\n",
    "            query_list.append(query_words[i][0])\n",
    "    \n",
    "    \n",
    "    for i in range(len(query_list)):\n",
    "        if query_list[i] not in invertedindex.keys():   \n",
    "            for key, value in variation_dict.items():\n",
    "                if query_list[i] in key:\n",
    "                    query_list[i] = variation_dict[key]\n",
    "            \n",
    "            corrected_token = spell_recommendation(query_list[i])\n",
    "\n",
    "            if corrected_token:\n",
    "                query_list[i]=corrected_token[0]\n",
    "\n",
    "    chapvers,doclist = newest_query(query_list, explanation)\n",
    "    \n",
    "    #print(query_list)\n",
    "    \n",
    "    ranks = ranking(doclist, query_list)\n",
    "    \n",
    "    return query_list, chapvers, doclist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59263ee",
   "metadata": {},
   "source": [
    "## Verse Suggestion \n",
    "In the following section, we will be implementing the feature of Verse suggestions. These suggestions are not part of the original results to a query, but rather further suggestions that might interest the user. The suggestions are calculated based on their similarity to other verses/explanations that are NOT in the result set but in the overall dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3dbedb",
   "metadata": {},
   "source": [
    "### Remove List Duplicates function\n",
    "The following cell will introduce a function to remove duplicates from a list without changing the order of the list. This will be important later on, where this functionality will be used to remove duplicate suggestions whilst keeping the order in tact, meaning that should a duplicate be encountered, the list will skip to the next most similar suggestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "576e78d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_list_duplicates(lst):\n",
    "    \"\"\"\n",
    "    takes any list with any sort of elements and maintains only unique element of the input list\n",
    "    while maintaining original list order\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    lst: list\n",
    "        any list with any number of elements and any sort of elements\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    cleaned_list: list\n",
    "        The original list with the same order where duplicate elements have been removed\n",
    "    \"\"\"\n",
    "    seen_set = set()\n",
    "    cleaned_list = [elem for elem in lst if elem not in seen_set and not seen_set.add(elem)]\n",
    "    return cleaned_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f1de2e",
   "metadata": {},
   "source": [
    "### Verse suggestion\n",
    "The following cells will output suggested verses for our queries based on similarity between either verses or explanations from the result set.\n",
    "\n",
    "First off, in the following cell, we're going to load the necessary verses and explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54416c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading spacy nlp objects from pickle files, this can take a moment...\n",
      "Completed!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "use_loaded_exp_prep_maps=1 #change this to 0 if you would like to run spacy mapping from scratch (can take >30mins)\n",
    "\n",
    "disjoint_explanations_prep=[]\n",
    "disjoint_explanations_unprep=[]\n",
    "disjoint_verses=[]\n",
    "\n",
    "if use_loaded_exp_prep_maps == 1:\n",
    "    \n",
    "    print('Loading spacy nlp objects from pickle files, this can take a moment...')\n",
    "    \n",
    "    with open(\"../pickle/disjoint_expl_prep\", \"rb\") as fp:   # Unpickling\n",
    "       disjoint_explanations_prep = pickle.load(fp)\n",
    "    \n",
    "    with open(\"../pickle/disjoint_expl_unprep\", \"rb\") as fp:   # Unpickling\n",
    "       disjoint_explanations_unprep = pickle.load(fp)\n",
    "    \n",
    "    with open(\"../pickle/disjoint_verses\", \"rb\") as fp:   # Unpickling\n",
    "       disjoint_verses = pickle.load(fp)\n",
    "    \n",
    "    print('Completed!')\n",
    "else :\n",
    "    \n",
    "    \n",
    "    all_explanations_prep = new_df[\"Clean_Text\"].tolist()\n",
    "    all_explanations_prep = [' '.join(ele) for ele in all_explanations_prep]\n",
    "    disjoints_prep = all_explanations_prep.copy()\n",
    "    disjoint_explanations_prep = [nlp(expl) for expl in disjoints_prep]\n",
    "    \n",
    "    all_explanations_unprep = new_df[\"Tafsir\"].tolist()    \n",
    "    disjoints_unprep = all_explanations_unprep.copy()\n",
    "    disjoint_explanations_unprep = [nlp(expl) for expl in disjoints_unprep]\n",
    "    \n",
    "    all_verses = new_df[\"Translation\"].tolist()\n",
    "    dj_verses = all_verses.copy()\n",
    "    disjoint_verses = [nlp(verse) for verse in dj_verses]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acdb4ab",
   "metadata": {},
   "source": [
    "Now we will introduce a function to map the explanations to spacy large's vector space. Likewise, we will introduce a function to do the same for the verses in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36400918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expl_spacy_map(docids, use_plain_explanations=False):\n",
    "    \"\"\"\n",
    "    maps the explanations in our dataset to spacy's vector space in the spacy large model\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    docids: list\n",
    "        a list containing the id's of the documents that were returned as results to a query\n",
    "    use_plain_explanations: bool\n",
    "        determines whether the preprocessed (False) or the unpreprocessed versions of the \n",
    "        explanations will be used.\n",
    "        The default is False.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    result_expl_list: list\n",
    "        a list of the result verses embedded in spacy's vector space\n",
    "    all_explanations: list\n",
    "        a list of all explanations embedded in spacy's vector space\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if use_plain_explanations is True:\n",
    "        #print('Using plain explanations...')\n",
    "        all_explanations = new_df[\"Tafsir\"].tolist()\n",
    "    else: \n",
    "        all_explanations = new_df[\"Clean_Text\"].tolist()\n",
    "        all_explanations = [' '.join(ele) for ele in all_explanations]\n",
    "        \n",
    "    \n",
    "    \n",
    "    result_expl_list=[]\n",
    "    \n",
    "    for i in docids:\n",
    "        #print(i)\n",
    "        result_expl_list.append(nlp(all_explanations[i]))\n",
    "\n",
    "        \n",
    "    return result_expl_list, all_explanations\n",
    "\n",
    "#result_expl_list, all_explanations = spacy_map1(ranks)\n",
    "\n",
    "def verse_spacy_map(ranks):\n",
    "    \"\"\"\n",
    "    maps all verses in our dataset into spacy's vector space in the large model\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ranks: list\n",
    "        a list of the ranked docids as results to a query\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    result_verse_list: list\n",
    "        a list of the input ranks list mapped to spacy's vector space\n",
    "    \n",
    "    all_verses: list\n",
    "        a list of all verses mapped to spacy's vector space\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    all_verses = new_df[\"Translation\"].tolist()\n",
    "    \n",
    "    result_verse_list = []\n",
    "    \n",
    "    for i in ranks:\n",
    "        #print(i)\n",
    "        result_verse_list.append(nlp(all_verses[i]))\n",
    "    \n",
    "    return result_verse_list, all_verses\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8139033b",
   "metadata": {},
   "source": [
    "## Explanation-Similarity for Suggestion \n",
    "The following cell will introduce a function for the explanation-based suggestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f2ea50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_explanations = new_df[\"Clean_Text\"].tolist()\n",
    "#all_explanations = [' '.join(ele) for ele in all_explanations]\n",
    "\n",
    "def max_explanation_sim_suggestion(docids, disjoint_explanations, result_expl_list,\n",
    "                                   max_suggestions=True, print_message=True, return_chap_verse=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    takes result verses of queries as input and suggests the most similar EXPLANATION as output\n",
    "    for the top 3 of the input verse list\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    docids : list\n",
    "        list of ids for the result verses of queries, can have arbitrary length\n",
    "    disjoint_explanations: list\n",
    "        list of all verses (i.e. their explanations) of \n",
    "        the results for a query have been \"filtered out\" by replacing their explanation.\n",
    "        with an empty string. Every other remainining verse has a vector representation via spaCy's \n",
    "        nlp pipeline\n",
    "    result_expl_list: list\n",
    "        list of all verses (i.e. their explanations) in the result set for a query. These too have been \n",
    "        put through spaCy's nlp pipeline and have a vector representation.\n",
    "    max_suggestions: bool\n",
    "        determines whether only the top 3 suggestion or the entire list of suggestions (as long as docids)\n",
    "        will be returned.\n",
    "        The default is False.\n",
    "    print_message: bool\n",
    "        determines whether a message for the user suggesting top 3 verses should be returned.\n",
    "        The default is True.\n",
    "    return_chap_verse: False\n",
    "        determines whether instead of the list of docids the list of chapter-verse tuples for the \n",
    "        suggestions will be returned.\n",
    "        The default is False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    extended_docids: list\n",
    "        list of original docids which is extended by exactly three elements, namely the top 3 suggestions.\n",
    "        Docids themselves are integers.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    expl_sims = []\n",
    "    #print(result_expl_list[0])\n",
    "    \n",
    "    for result_expl in result_expl_list: \n",
    "        \n",
    "        expl_similarities = [result_expl.similarity(expl) for expl in disjoint_explanations]\n",
    "        expl_similarities[:] = [x if x != 1 else 0 for x in expl_similarities]\n",
    "        expl_sims.append(expl_similarities)\n",
    "        \n",
    "    #print(expl_sims)\n",
    "    \n",
    "        \n",
    "    #get most index of most similar verse for each verse in query result list\n",
    "    most_sim_expl_index_list = [expl_list.index(max(expl_list)) for expl_list in expl_sims]\n",
    "    most_sim_chapter_list = [new_df[\"Chapter\"].iloc[expl] for expl in most_sim_expl_index_list]\n",
    "    most_sim_verse_list = [new_df[\"Verse\"].iloc[expl] for expl in most_sim_expl_index_list]\n",
    "    most_sim_tuple_list = list(zip(most_sim_chapter_list, most_sim_verse_list))\n",
    "    \n",
    "    #remove duplicates --> since order will be preserved, list will skip to next highest ranked elem\n",
    "    most_sim_expl_index_list_cleaned = remove_list_duplicates(most_sim_expl_index_list)\n",
    "    most_sim_tuple_list_cleaned = remove_list_duplicates(most_sim_tuple_list)\n",
    "    \n",
    "    #append docids of top 3 suggestions to docids\n",
    "    extended_docids = docids.copy()\n",
    "    for index in most_sim_expl_index_list_cleaned[:3]:\n",
    "        extended_docids.append(index)\n",
    "    \n",
    "    #set to True if more than 3 results suggestions shall be returned\n",
    "    if max_suggestions is False:\n",
    "        final_chap_verse_tup_list = most_sim_tuple_list_cleaned\n",
    "        for elem in most_sim_expl_index_list_cleaned:\n",
    "            extended_docids.append(elem)\n",
    "    else:\n",
    "        final_chap_verse_tup_list = most_sim_tuple_list_cleaned[:3]\n",
    "    \n",
    "    if print_message is False:\n",
    "        return extended_docids\n",
    "    #else:\n",
    "        #print(\"You might also be interested in the following verses: \\n\")\n",
    "        #print(\"\\n\".join(\"Chapter {}, Verse {}\".format(*tup) for tup in final_chap_verse_tup_list))\n",
    "    \n",
    "    if return_chap_verse is True:\n",
    "        return final_chap_verse_tup_list\n",
    "    else:\n",
    "        return extended_docids\n",
    "\n",
    "#max_explanation_suggestion = max_explanation_sim_suggestion(ranks, disjoint_explanations, result_expl_list)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "043bf38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverted_explanation_results(query, disjoint_explanations, use_plain_explanations=False):\n",
    "    \"\"\"\n",
    "    returns the results from the inverted index for input queries and suggests \n",
    "    based on explanations similarity\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    query: str\n",
    "        Any input query (in our case those formulated in our dataset)\n",
    "    disjoint_explanations list\n",
    "        a list of all explanations which are NOT in the result set\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    chapvers: \n",
    "    \n",
    "    max_explanation_suggestion: list\n",
    "        a list of the ids of the verse suggestions\n",
    "    Additionally, the function prints the suggested chapters and verses\n",
    "    \"\"\"\n",
    "    \n",
    "    query_dict = {}\n",
    "    i=0\n",
    "        \n",
    "    query_list, chapvers, docids = boolean_retrieval(query)\n",
    "    #print(docids)\n",
    "    ranks, chapvers = ranking(docids, query_list)\n",
    "        \n",
    "    result_expl_list, all_explanations = expl_spacy_map(ranks, use_plain_explanations=use_plain_explanations)\n",
    "        \n",
    "    max_explanation_suggestion = max_explanation_sim_suggestion(ranks, disjoint_explanations, result_expl_list)\n",
    "        \n",
    "        \n",
    "    for suggestions in max_explanation_suggestion:\n",
    "        ranks.append(suggestions)\n",
    "        \n",
    "    query_dict[query] = ranks\n",
    "        \n",
    "    print('\\n')\n",
    "        \n",
    "    return chapvers, max_explanation_suggestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d9b2b4",
   "metadata": {},
   "source": [
    "## Verse-Similarity for Suggestion\n",
    "The following cell will introduce a verse-similarity-based function for suggestions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12938d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Similarity Verses\n",
    "\n",
    "#all_verses = new_df['Translation'].to_list()\n",
    "\n",
    "def max_verse_sim_suggestion(docids, disjoint_verses, result_verse_list, \n",
    "                             max_suggestions=True, print_message=True, return_chap_verse=True):\n",
    "    \"\"\"\n",
    "    takes result verses of queries as input and suggests the most similar verse as output\n",
    "    for the top 3 of the input verse list\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    docids : list\n",
    "        list of ids for the result verses of queries, can have arbitrary length\n",
    "    all_verses: list\n",
    "        list of all verses where each element is a string, namely the verse itself\n",
    "    max_suggestions: bool\n",
    "        determines whether only the top 3 suggestion or the entire list of suggestions (as long as docids)\n",
    "        will be returned.\n",
    "        The default is False.\n",
    "    print_message: bool\n",
    "        determines whether a message for the user suggesting top 3 verses should be returned.\n",
    "        The default is True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    extended_docids: list\n",
    "        list of original docids which is extended by exactly three elements, namely the top 3 suggestions.\n",
    "        Docids themselves are integers.\n",
    "    \n",
    "    \"\"\"\n",
    "        \n",
    "    verse_sims = [] #create list of verse similarities for each verse\n",
    "    for result_verse in result_verse_list:\n",
    "        similarities = [result_verse.similarity(verse) for verse in disjoint_verses]\n",
    "        similarities[:] = [v if v != 1 else 0 for v in similarities]\n",
    "        verse_sims.append(similarities)\n",
    "        \n",
    "    #get max elements of each verse list only (for suggestions) --> most similar verse for each verse\n",
    "    most_sim_index_list = [verse_list.index(max(verse_list)) for verse_list in verse_sims]\n",
    "    #get chapter numbers of each most simlar verse\n",
    "    most_sim_chapter_list = [new_df[\"Chapter\"].iloc[most_sim] for most_sim in most_sim_index_list]\n",
    "    #get verse numbers of each most similar verse\n",
    "    most_sim_verse_list = [new_df[\"Verse\"].iloc[most_sim] for most_sim in most_sim_index_list]\n",
    "    most_sim_tuple_list = list(zip(most_sim_chapter_list, most_sim_verse_list))\n",
    "    \n",
    "    #remove duplicates --> since order will be preserved, list will skip to next highest ranked elem\n",
    "    most_sim_index_list_cleaned = remove_list_duplicates(most_sim_index_list)\n",
    "    most_sim_tuple_list_cleaned = remove_list_duplicates(most_sim_tuple_list)\n",
    "       \n",
    "    #append docids of top 3 suggestions to docids\n",
    "    extended_docids = docids.copy()\n",
    "    for index in most_sim_index_list_cleaned[:3]:\n",
    "        extended_docids.append(index)\n",
    "    \n",
    "    #set to True if more than 3 results suggestions shall be returned\n",
    "    if max_suggestions is False:\n",
    "        final_chap_verse_tup_list = most_sim_tuple_list_cleaned\n",
    "        for elem in most_sim_index_list_cleaned:\n",
    "            extended_docids.append(elem)\n",
    "    else:\n",
    "        final_chap_verse_tup_list = most_sim_tuple_list_cleaned[:3]\n",
    "    \n",
    "    #decide whether message will be printed or not\n",
    "    if print_message is False:\n",
    "        return extended_docids\n",
    "    #else:\n",
    "        #print(\"You might also be interested in the following verses: \\n\")\n",
    "        #print(\"\\n\".join(\"Chapter {}, Verse {}\".format(*tup) for tup in final_chap_verse_tup_list))\n",
    "    \n",
    "    if return_chap_verse is True:\n",
    "        return final_chap_verse_tup_list\n",
    "    else:\n",
    "        return extended_docids\n",
    "    \n",
    "    \n",
    "#verse_suggestion = max_verse_sim_suggestion(ranks, disjoint_verses, result_verse_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a37721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverted_verse_results(query, disjoint_verses):\n",
    "    \"\"\"\n",
    "    returns the results from the inverted index for input queries\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    query: str\n",
    "        Any input query (in our case those formulated in our dataset)\n",
    "    disjoint_verses: list\n",
    "        a list of all verses which are NOT in the result set\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    chapvers: \n",
    "    \n",
    "    max_verse_suggestion: list\n",
    "        a list of the ids of the verse suggestions\n",
    "    Additionally, the function prints the suggested chapters and verses\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    query_dict = {}\n",
    "    i=0\n",
    "        \n",
    "    query_list, chapvers, docids = boolean_retrieval(query)\n",
    "    #print(docids)\n",
    "    ranks, chapvers = ranking(docids, query_list)\n",
    "        \n",
    "    result_verse_list, all_verses = verse_spacy_map(ranks)\n",
    "        \n",
    "    max_verse_suggestion = max_verse_sim_suggestion(ranks, disjoint_verses, result_verse_list)\n",
    "        \n",
    "    list=[]\n",
    "    for suggestions in max_verse_suggestion:\n",
    "        #print(suggestions)\n",
    "        list.append(suggestions)\n",
    "        \n",
    "    #print(ranks)\n",
    "    query_dict[query] = ranks\n",
    "        \n",
    "    print('\\n')\n",
    "        \n",
    "    return chapvers, max_verse_suggestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da7573a",
   "metadata": {},
   "source": [
    "## Main Code and Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3444fe64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query : moses and pharoah\n",
      "\n",
      "\n",
      "Results :\n",
      "Chapter 1, Verse 2\n",
      "Chapter 2, Verse 52\n",
      "Chapter 2, Verse 53\n",
      "Chapter 2, Verse 51\n",
      "\n",
      "You might also be interested in the following verses: \n",
      "\n",
      "Chapter 4, Verse 171\n",
      "Chapter 5, Verse 44\n"
     ]
    }
   ],
   "source": [
    "use_verse_suggestion = 3 #(1 = verse similarity, 2 = preprocessed explanation similarity, 3 = unpreprocessed similarity)\n",
    "\n",
    "query = 'moses and pharoah'\n",
    "\n",
    "if use_verse_suggestion == 1:\n",
    "    \n",
    "    results, suggestion = inverted_verse_results(query, disjoint_verses)\n",
    "    \n",
    "    print('Results :')\n",
    "    print(\"\\n\".join(\"Chapter {}, Verse {}\".format(*tup) for tup in results))       \n",
    "    \n",
    "    print(\"\\nYou might also be interested in the following verses: \\n\")\n",
    "    print(\"\\n\".join(\"Chapter {}, Verse {}\".format(*tup) for tup in suggestion))\n",
    "    \n",
    "    \n",
    "if use_verse_suggestion == 2:\n",
    "    \n",
    "    results, suggestion = inverted_explanation_results(query, disjoint_verses)\n",
    "    #print(results)\n",
    "    \n",
    "    print('Results :')\n",
    "    print(\"\\n\".join(\"Chapter {}, Verse {}\".format(*tup) for tup in results))      \n",
    "    \n",
    "    print(\"\\nYou might also be interested in the following verses: \\n\")\n",
    "    print(\"\\n\".join(\"Chapter {}, Verse {}\".format(*tup) for tup in suggestion))     \n",
    "    \n",
    "    \n",
    "if use_verse_suggestion == 3:\n",
    "    results, suggestion = inverted_explanation_results(query, disjoint_verses, use_plain_explanations=True)\n",
    "    #print(results)\n",
    "    \n",
    "    print('Results :')\n",
    "    print(\"\\n\".join(\"Chapter {}, Verse {}\".format(*tup) for tup in results))      \n",
    "    \n",
    "    print(\"\\nYou might also be interested in the following verses: \\n\")\n",
    "    print(\"\\n\".join(\"Chapter {}, Verse {}\".format(*tup) for tup in suggestion)) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3082fad4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533ca9ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcb2a10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
